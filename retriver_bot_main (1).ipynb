{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWQAtzR7C2M2"
      },
      "source": [
        "# **Install Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1NJdqr94Ai",
        "outputId": "17d7ea59-0d59-40ab-dfcd-0e0ea189f567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: FastAPI in /usr/local/lib/python3.10/dist-packages (0.115.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (24.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.17)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.142)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.54.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.5.18)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (0.41.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.28.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.67.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.13.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.1.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.28.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.49b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.26.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (14.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langchain-openai  langchain-community  langchain-chroma tiktoken FastAPI uvicorn pyngrok nest_asyncio aiofiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPYxwf_mC0hT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models  import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage, ChatMessage\n",
        "from fastapi import FastAPI, Request\n",
        "from fastapi.responses import JSONResponse\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import aiofiles\n",
        "import json\n",
        "import asyncio\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "_KBGs_nRDFWF",
        "outputId": "9cf3e858-29ed-4a88-b47a-da390364415d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-078dd0c7-5e06-46e2-8e40-b1b6272dfef1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-078dd0c7-5e06-46e2-8e40-b1b6272dfef1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving csee_scraped_data.csv to csee_scraped_data.csv\n",
            "Saving isss_scraped_data.csv to isss_scraped_data.csv\n",
            "Saving dil_scraped_data.csv to dil_scraped_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qZERptBIDLW6",
        "outputId": "bf07c228-54d6-443e-e66c-9155bfea1d6e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Working Off-Campus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Link\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://isss.umbc.edu/international-students-f-1/current-students-employment/working-off-campus/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I\\u2019m currently on CPT, but I want to change internships or work with a different employer. What are the next steps?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Complete and submit another CPT request for the new position. If you enrolled in PRAC, let the Career Center know of your change in plans.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-99cf180e-99cb-421c-884c-683afccfdee4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Section</th>\n",
              "      <th>Link</th>\n",
              "      <th>Title</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>Working Off-Campus</td>\n",
              "      <td>https://isss.umbc.edu/international-students-f...</td>\n",
              "      <td>I’m in my final semester. Can I do full time CPT?</td>\n",
              "      <td>Yes, but only if you are enrolled in 4 credits...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>Working Off-Campus</td>\n",
              "      <td>https://isss.umbc.edu/international-students-f...</td>\n",
              "      <td>I’m currently on CPT, but I want to change int...</td>\n",
              "      <td>Complete and submit another CPT request for th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Working Off-Campus</td>\n",
              "      <td>https://isss.umbc.edu/international-students-f...</td>\n",
              "      <td>I decided to extend my internship into the nex...</td>\n",
              "      <td>If you are continuing the same job position in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>Working Off-Campus</td>\n",
              "      <td>https://isss.umbc.edu/international-students-f...</td>\n",
              "      <td>I’m extending my internship until the end of t...</td>\n",
              "      <td>You do not need to submit another CPT request ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>Working Off-Campus</td>\n",
              "      <td>https://isss.umbc.edu/international-students-f...</td>\n",
              "      <td>What about taxes?</td>\n",
              "      <td>Paid work in the US is almost always taxed. Yo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99cf180e-99cb-421c-884c-683afccfdee4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99cf180e-99cb-421c-884c-683afccfdee4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99cf180e-99cb-421c-884c-683afccfdee4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-50bc67fe-29b0-4cd8-8192-069517970862\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50bc67fe-29b0-4cd8-8192-069517970862')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-50bc67fe-29b0-4cd8-8192-069517970862 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                Section                                               Link  \\\n",
              "146  Working Off-Campus  https://isss.umbc.edu/international-students-f...   \n",
              "147  Working Off-Campus  https://isss.umbc.edu/international-students-f...   \n",
              "148  Working Off-Campus  https://isss.umbc.edu/international-students-f...   \n",
              "149  Working Off-Campus  https://isss.umbc.edu/international-students-f...   \n",
              "150  Working Off-Campus  https://isss.umbc.edu/international-students-f...   \n",
              "\n",
              "                                                 Title  \\\n",
              "146  I’m in my final semester. Can I do full time CPT?   \n",
              "147  I’m currently on CPT, but I want to change int...   \n",
              "148  I decided to extend my internship into the nex...   \n",
              "149  I’m extending my internship until the end of t...   \n",
              "150                                  What about taxes?   \n",
              "\n",
              "                                                  Text  \n",
              "146  Yes, but only if you are enrolled in 4 credits...  \n",
              "147  Complete and submit another CPT request for th...  \n",
              "148  If you are continuing the same job position in...  \n",
              "149  You do not need to submit another CPT request ...  \n",
              "150  Paid work in the US is almost always taxed. Yo...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dil_data = pd.read_csv('dil_scraped_data.csv')\n",
        "isss_data = pd.read_csv('isss_scraped_data.csv')\n",
        "csee_data =pd.read_csv('csee_scraped_data.csv')\n",
        "# Concatenate the DataFrames\n",
        "data = pd.concat([dil_data, isss_data], ignore_index=True)\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyrAVm5qDWER"
      },
      "source": [
        "# **Authentication**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWZua3QqDSxk"
      },
      "outputs": [],
      "source": [
        "# Set up OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "#Ngrok\n",
        "ngrok_auth = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXfJiDafDZ38"
      },
      "source": [
        "# **Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocbZXJBkDXyz",
        "outputId": "e5cf38fb-a0f3-4964-dbd7-cd93b2eb406a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data added to Chroma and saved to disk.\n"
          ]
        }
      ],
      "source": [
        "# Define a persistent directory\n",
        "persist_directory = \"chroma_store\"\n",
        "\n",
        "# Initialize OpenAI embeddings and Chroma with persistence\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "chroma_store = Chroma(\n",
        "    collection_name=\"retriever_bot\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "# Ensure data[\"Text\"] is string formatted\n",
        "data[\"Text\"] = data[\"Text\"].astype(str)\n",
        "\n",
        "# Split text into manageable chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=100\n",
        ")\n",
        "\n",
        "# Process each row in the dataset and add to Chroma\n",
        "for idx, row in data.iterrows():\n",
        "    # Split the text into chunks\n",
        "    chunks = text_splitter.split_text(row[\"Text\"])\n",
        "\n",
        "    # Prepare metadata with Section, Link, and Title\n",
        "    metadata = {\n",
        "        \"section\": row[\"Section\"],\n",
        "        \"link\": row[\"Link\"],\n",
        "        \"title\": row[\"Title\"]\n",
        "    }\n",
        "\n",
        "    # Add each chunk with metadata and embedding to Chroma\n",
        "    chroma_store.add_texts(\n",
        "        texts=chunks,\n",
        "        metadatas=[metadata] * len(chunks)  # Repeat metadata for each chunk\n",
        "    )\n",
        "\n",
        "print(\"Data added to Chroma and saved to disk.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m7fXJZgDkAt",
        "outputId": "d32c9841-e21d-4e36-99b4-98932734ea83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Research data added to Chroma and saved to disk.\n"
          ]
        }
      ],
      "source": [
        "# Initialize another persistent directory\n",
        "persist_directory_research = \"chroma_store1\"\n",
        "\n",
        "# Initialize Chroma with persistence for research data\n",
        "chroma_store1 = Chroma(\n",
        "    collection_name=\"research_info\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=persist_directory_research\n",
        ")\n",
        "\n",
        "# Process each row in the dataset for research info\n",
        "for idx, row in csee_data.iterrows():\n",
        "    # Prepare metadata with Section, Link, and Title\n",
        "    metadata = {\n",
        "        \"section\": row[\"Section\"],\n",
        "        \"link\": row[\"Link\"],\n",
        "        \"title\": row[\"Title\"]\n",
        "    }\n",
        "\n",
        "    # Add full text with metadata to Chroma without chunking\n",
        "    chroma_store1.add_texts(\n",
        "        texts=[row[\"Text\"]],\n",
        "        metadatas=[metadata]\n",
        "    )\n",
        "\n",
        "print(\"Research data added to Chroma and saved to disk.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkm7_mvQEVrU"
      },
      "source": [
        "# **Main Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot2gPdGEEQf_",
        "outputId": "274ea8aa-7589-4f82-d92e-c3813e00ff1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://5144-34-16-234-184.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "ngrok.set_auth_token(ngrok_auth)\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAILXZZpE7gf"
      },
      "outputs": [],
      "source": [
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Define persistence directories for Chroma\n",
        "persist_directory_retriever = \"chroma_store\"\n",
        "persist_directory_research = \"chroma_store1\"\n",
        "\n",
        "# Initialize OpenAI embeddings and Chroma vector stores\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "chroma_store = Chroma(\n",
        "    collection_name=\"retriever_bot\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=persist_directory_retriever\n",
        ")\n",
        "chroma_store1 = Chroma(\n",
        "    collection_name=\"research_info\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=persist_directory_research\n",
        ")\n",
        "\n",
        "# Initialize memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",output_key=\"answer\",return_messages=True)\n",
        "\n",
        "# Global variables\n",
        "last_intent = None\n",
        "interaction_count = 0\n",
        "feedback_requested = False\n",
        "pending_conversation_data = None  # Variable to hold conversation data awaiting feedback\n",
        "feedback_timeout_counter = 0       # Counter for feedback prompt retries\n",
        "MAX_FEEDBACK_PROMPTS = 2           # Maximum number of feedback prompts before giving up\n",
        "\n",
        "\n",
        "# Define the lists of affirmative and negative responses\n",
        "affirmative_responses = [\n",
        "    \"yes\", \"yup\", \"yeah\", \"absolutely\", \"definitely\", \"sure\",\n",
        "    \"yes, this is helpful\", \"it's helpful\", \"very helpful\", \"indeed\",\n",
        "    \"positive\", \"certainly\", \"of course\", \"thank you\", \"this is great\", \"glad\"\n",
        "]\n",
        "\n",
        "negative_responses = [\n",
        "    \"no\", \"nope\", \"not really\", \"not at all\", \"negative\",\n",
        "    \"unfortunately not\", \"it's not helpful\", \"no, not helpful\",\n",
        "    \"no thanks\", \"nah\", \"not quite\", \"don't think so\", \"disappointed\", \"bad\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EomaX8XnFcbk"
      },
      "source": [
        "Function to save conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FRxT2ggFHRH"
      },
      "outputs": [],
      "source": [
        "async def save_conversation_history(conversation_data):\n",
        "    # Process the chat_history to make it JSON serializable\n",
        "    processed_chat_history = []\n",
        "    for message in conversation_data['chat_history']:\n",
        "        if isinstance(message, HumanMessage):\n",
        "            processed_chat_history.append({\n",
        "                'type': 'human',\n",
        "                'content': message.content\n",
        "            })\n",
        "        elif isinstance(message, AIMessage):\n",
        "            processed_chat_history.append({\n",
        "                'type': 'ai',\n",
        "                'content': message.content\n",
        "            })\n",
        "        else:\n",
        "            # Handle other message types if necessary\n",
        "            processed_chat_history.append({\n",
        "                'type': 'other',\n",
        "                'content': message.content\n",
        "            })\n",
        "    # Replace the chat_history with the processed version\n",
        "    conversation_data['chat_history'] = processed_chat_history\n",
        "\n",
        "    # Now it's safe to serialize conversation_data to JSON\n",
        "    async with aiofiles.open(\"conversation_history.json\", mode=\"a\") as file:\n",
        "        await file.write(json.dumps(conversation_data) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5P1sJbzFn3a"
      },
      "source": [
        "Intent Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hrf2qUMFm7k"
      },
      "outputs": [],
      "source": [
        "def get_parent_intent(intent_name):\n",
        "    \"\"\"\n",
        "    Returns the parent intent for a given intent. If the intent is a parent intent, returns itself.\n",
        "\n",
        "    Args:\n",
        "        intent_name (str): The name of the intent to check.\n",
        "\n",
        "    Returns:\n",
        "        str: The parent intent name.\n",
        "    \"\"\"\n",
        "    # Intent mapping dictionary\n",
        "    intent_mapping = {\n",
        "        \"Get_Course_info\": {\n",
        "            \"sub_intents\": [\n",
        "                \"Get_Course_info - custom\"\n",
        "            ]\n",
        "        },\n",
        "        \"Get_CPT_OPT_Info\": {\n",
        "            \"sub_intents\": [\n",
        "                \"Get_CPT_Application_Process\",\n",
        "                \"Get_CPT_OPT_Documents\",\n",
        "                \"Get_OPT_Application_Process\",\n",
        "                \"Get_CPT_Eligibility\",\n",
        "                \"Get_OPT_Eligibility\"\n",
        "            ]\n",
        "        },\n",
        "        \"Get_General_Info\": {\n",
        "            \"sub_intents\": [\n",
        "                \"Get_General_Info - custom\"\n",
        "            ]\n",
        "        },\n",
        "        \"Get_Research_Info\": {\n",
        "            \"sub_intents\": [\n",
        "                \"Get_Research_Faculty_Info\",\n",
        "                \"Get_Research_Info - custom\"\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Iterate through the mapping to find the parent intent\n",
        "    for parent_intent, details in intent_mapping.items():\n",
        "        if intent_name == parent_intent or intent_name in details[\"sub_intents\"]:\n",
        "            return parent_intent\n",
        "\n",
        "    # If no match is found, return None\n",
        "    return intent_name\n",
        "\n",
        "def handle_intent_change(intent_name: str):\n",
        "    \"\"\"\n",
        "    Handles changes in user intent and manages interaction counts.\n",
        "    Sets feedback_requested flag when intent changes or interaction count exceeds threshold.\n",
        "    \"\"\"\n",
        "    global last_intent, interaction_count, feedback_requested, pending_conversation_data, feedback_timeout_counter\n",
        "\n",
        "    if last_intent is not None and last_intent != intent_name:\n",
        "        # Intent has changed\n",
        "        feedback_requested = True\n",
        "        feedback_timeout_counter = 0  # Reset the feedback timeout counter\n",
        "        # Store the previous conversation data\n",
        "        pending_conversation_data = {\n",
        "            \"intent\": last_intent,\n",
        "            \"chat_history\": memory.chat_memory.messages.copy(),\n",
        "            \"feedback\": None\n",
        "        }\n",
        "        interaction_count = 0  # Reset interaction count for new intent\n",
        "    else:\n",
        "        # Same intent, increment interaction count\n",
        "        interaction_count += 1\n",
        "        if interaction_count >= 5:\n",
        "            feedback_requested = True\n",
        "            feedback_timeout_counter = 0  # Reset the feedback timeout counter\n",
        "            # Store the current conversation data\n",
        "            pending_conversation_data = {\n",
        "                \"intent\": intent_name,\n",
        "                \"chat_history\": memory.chat_memory.messages.copy(),\n",
        "                \"feedback\": None\n",
        "            }\n",
        "            interaction_count = 0  # Reset after requesting feedback\n",
        "\n",
        "    last_intent = intent_name  # Update to the new intent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3w9BTFmGMH9"
      },
      "source": [
        " HyperLinks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMU8lW5rF5XK"
      },
      "outputs": [],
      "source": [
        "def user_is_asking_for_link(query):\n",
        "    keywords = [\"link\", \"source\", \"reference\",\"find\" , \"references\",\"sources\",\"url\", \"where can I find\", \"can you provide the link\"]\n",
        "    query_lower = query.lower()\n",
        "    return any(keyword in query_lower for keyword in keywords)\n",
        "\n",
        "def extract_links_from_source_docs(source_docs):\n",
        "    links = []\n",
        "    seen_links = set()  # Set to track unique links\n",
        "\n",
        "    for doc in source_docs:\n",
        "        try:\n",
        "            metadata = doc.metadata if isinstance(doc.metadata, dict) else {}\n",
        "            link = metadata.get(\"link\")\n",
        "            title = metadata.get(\"title\")\n",
        "\n",
        "            # Only add unique links\n",
        "            if link and link not in seen_links:\n",
        "                links.append((title, link))\n",
        "                seen_links.add(link)\n",
        "        except AttributeError:\n",
        "            # Handle the case where doc.metadata is not accessible\n",
        "            continue\n",
        "\n",
        "    return links\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-kWwzslY61a"
      },
      "source": [
        "LLM prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4yZ9jCKI2pi"
      },
      "outputs": [],
      "source": [
        "# Load LLM model\n",
        "def load_llm():\n",
        "    return ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "\n",
        "def get_user_messages(memory):\n",
        "    user_messages = []\n",
        "    for msg in memory.chat_memory.messages:\n",
        "        if msg.type == 'human':\n",
        "            user_messages.append(msg.content)\n",
        "    return '\\n'.join(user_messages)\n",
        "\n",
        "def load_prompt(intent_name):\n",
        "    if intent_name == \"Get_Course_info\":\n",
        "        prompt = \"\"\"You need to answer the user's question about course related and  prerequisites information.\n",
        "         Use the conversation history to provide a consistent response.\n",
        "        Conversation History: {chat_history}\n",
        "        Context: {context}\n",
        "        Question: {question}\"\"\"\n",
        "    elif intent_name == \"Get_CPT_OPT_info\":\n",
        "        prompt = \"\"\"You need to answer the user's question about CPT or OPT information based on the given context only.\n",
        "        Give friendly responses.\n",
        "        Use the conversation history to provide a consistent response.\n",
        "        Conversation History: {chat_history}\n",
        "        Context: {context}\n",
        "        Question: {question}\"\"\"\n",
        "    elif intent_name == \"Get_General_info\":\n",
        "        prompt = \"\"\"You are a helpful assistant for students, here to provide accurate answers strictly based on the provided context.\n",
        "        Do not create or infer any information that isn’t explicitly in the context. If the answer cannot be found within the context, respond with a polite message indicating that additional information is needed and prompt the student to either rephrase their question or clarify. If applicable, you may suggest specific topics or terms that could help refine the search.\n",
        "        Context: {context}\n",
        "        Student's Question: {question}\n",
        "        Use the conversation history to provide a consistent response.\n",
        "        Conversation History: {chat_history}\n",
        "        Example Response (when information is missing):\n",
        "        I couldn't find a direct answer in the provided information. Could you provide more details or rephrase your question? You might also consider specifying terms or topics to help refine the search.\"\"\"\n",
        "\n",
        "    elif intent_name == \"Get_Research_info\":\n",
        "        prompt = \"\"\"You need to answer the user's question about research information. Please dont assume answer only based on the context given\n",
        "        Use the conversation history to provide a consistent response.\n",
        "        Conversation History: {chat_history}\n",
        "        Context: {context}\n",
        "        Question: {question}\"\"\"\n",
        "    else:\n",
        "        prompt = \"\"\"You need to answer the user's question.\n",
        "        Use the conversation history to provide a consistent response.\n",
        "        Conversation History: {chat_history}\n",
        "        Context: {context}\n",
        "        Question: {question}\"\"\"\n",
        "    return ChatPromptTemplate.from_template(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8yLsnvSakkR"
      },
      "source": [
        "Retriever Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6noBo0Qm7l8"
      },
      "outputs": [],
      "source": [
        "def is_syllabus_query(query: str) -> bool:\n",
        "    \"\"\"\n",
        "    Determines if the query is related to syllabus information.\n",
        "\n",
        "    :param query: User's query string.\n",
        "    :return: True if syllabus-related, False otherwise.\n",
        "    \"\"\"\n",
        "    syllabus_keywords = [\"syllabus\", \"course outline\", \"course structure\", \"course syllabus\", \"course outline\", \"course outcomes\"]\n",
        "    query_lower = query.lower()\n",
        "    return any(keyword in query_lower for keyword in syllabus_keywords)\n",
        "\n",
        "\n",
        "def get_full_course_title(course_input):\n",
        "    course_mapping = {\n",
        "  \"data 601\": \"DATA 601 Introduction to Data Science\",\n",
        "  \"data 602\": \"DATA 602 Introduction to Data Analysis and Machine Learning\",\n",
        "  \"data 603\": \"DATA 603 Platforms for Big Data Processing\",\n",
        "  \"data 604\": \"DATA 604 Data Management\",\n",
        "  \"data 605\": \"DATA 605 Ethical Legal Issues in Data Science\",\n",
        "  \"data 606\": \"DATA 606 Capstone in Data Science\",\n",
        "  \"data 607\": \"DATA 607 Leadership in Data Science\",\n",
        "  \"data 608\": \"DATA 608 Probability and Statistics for Data Science\",\n",
        "  \"data 690\": \"DATA 690 Special Topics: Statistical Analysis and Visualization with Python\",\n",
        "  \"data 690\": \"DATA 690 Special Topics: Mathematical Foundations for Machine Learning\",\n",
        "  \"data 690\": \"DATA 690 Special Topics: Data Structures and Algorithms in Python\",\n",
        "  \"data 690\": \"DATA 690 Special Topics: Applied Machine Learning with MATLAB\",\n",
        "  \"data 690\": \"DATA 690 Special Topics: Designing Data Driven Web Applications\",\n",
        "  \"data 690\": \"DATA 690 Financial Data Science\",\n",
        "  \"data 690\": \"DATA 690 Special Topic: Modern Practical Deep Learning\",\n",
        "  \"data 690\": \"DATA 690 Special Topics: Introduction to Natural Language Processing\",\n",
        "  \"data 690\": \"DATA 690 Special Topics: Artificial Intelligence for Practitioners\",\n",
        "  \"data 696\": \"DATA 696 Independent Study for Interns and Co-op Students\",\n",
        "  \"data 699\": \"DATA 699 Independent Study in Data Science\",\n",
        "  \"data 613\": \"DATA 613 – Data Visualization and Communication\",\n",
        "  \"data 621\": \"DATA 621 – Practical Deep Learning\"}\n",
        "    # Normalize input\n",
        "    course_input_lower = course_input.lower()\n",
        "\n",
        "    # First, try exact match in keys (course IDs)\n",
        "    for course_id in course_mapping.keys():\n",
        "        if course_id.lower() == course_input_lower:\n",
        "            return course_mapping[course_id]\n",
        "\n",
        "    # Then, try exact match in values (course titles)\n",
        "    for course_title in course_mapping.values():\n",
        "        if course_title.lower() == course_input_lower:\n",
        "            return course_title\n",
        "\n",
        "    # No match found\n",
        "    return None\n",
        "\n",
        "async def retrieve_syllabus_documents(course_titles):\n",
        "    # Build the metadata filter\n",
        "    metadata_filter = {\"title\": {\"$in\": course_titles}}\n",
        "\n",
        "    # Perform similarity search with the filter\n",
        "    try:\n",
        "        results = chroma_store.similarity_search(\"\", k=5, filter=metadata_filter)\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error during syllabus retrieval: {e}\")\n",
        "        return []\n",
        "# Load LLM model\n",
        "def load_llm():\n",
        "    return ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "\n",
        "async def handle_syllabus_query(query: str, parameters: dict,memory) -> dict:\n",
        "    # Extract course name from parameters\n",
        "    course_inputs = parameters.get(\"Course_name\", [])\n",
        "    if not course_inputs:\n",
        "        return \"Please specify the course name or ID for which you want the syllabus.\"\n",
        "    print(course_inputs)\n",
        "    # Get the full course title from the input\n",
        "    course_titles = [get_full_course_title(course_input) for course_input in course_inputs]\n",
        "    print('Here are the course titles: ',course_titles)\n",
        "    # Retrieve syllabus documents\n",
        "    retrieved_docs = await retrieve_syllabus_documents(course_titles)\n",
        "    if not retrieved_docs:\n",
        "        return \"Sorry, I couldn't find the syllabus for the specified course.\"\n",
        "\n",
        "    # Prepare the context from the retrieved documents\n",
        "    context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "   # Construct the prompt for the LLM\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful assistant that organizes syllabus information into a clear and concise tabular format. Based on the context provided, generate a week-by-week syllabus for each course mentioned in the query. Use readable and well-structured text in the table.\n",
        "\n",
        "        Context:{context}\n",
        "        Question: {query}\n",
        "        Format the answer as follows:\n",
        "        | Week | Topic Description |\n",
        "        |------|-------------------|\n",
        "        | 1    | Topic details     |\n",
        "        | 2    | Topic details     |\n",
        "        ...\n",
        "        Ensure that:\n",
        "        1. Each course has its own section in the table.\n",
        "        2. The information is concise and well-organized.\n",
        "        3. If a course does not have sufficient details in the context, indicate it with \"Details not available.\"\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "    # Generate the answer using the LLM\n",
        "    try:\n",
        "        response =  load_llm().invoke([prompt])\n",
        "        memory.chat_memory.add_user_message(query)\n",
        "        memory.chat_memory.add_ai_message(response)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during LLM generation: {e}\")\n",
        "        return {\"response\": \"An error occurred while generating the syllabus response.\"}\n",
        "\n",
        "    return {\"answer\": response.content, \"source_documents\": retrieved_docs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOhLoUkKaSrX"
      },
      "outputs": [],
      "source": [
        "# Function to select the retriever based on the intent\n",
        "def select_retriever(intent_name):\n",
        "    if intent_name == \"Get_Research_info\":\n",
        "        return chroma_store1.as_retriever(search_type=\"similarity\", search_kwargs={'k': 5})\n",
        "    else:\n",
        "        return chroma_store.as_retriever(search_type=\"similarity\", search_kwargs={'k': 5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GeivLJGTZHA"
      },
      "source": [
        "Webhook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxtymuhqSE92",
        "outputId": "1f3816de-fa27-4016-e0b7-4999e0abf96d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-119' coro=<Server.serve() done, defined at /usr/local/lib/python3.10/dist-packages/uvicorn/server.py:67> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\", line 579, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 65, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 315, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 68, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 332, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "INFO:     Started server process [1283]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received query: Can you tell me the syllabus for DATA 602 | Intent: Get_Course_info\n",
            "True matches criteria\n",
            "['DATA 602']\n",
            "Here are the course titles:  ['DATA 602 Introduction to Data Analysis and Machine Learning']\n",
            "INFO:     66.249.83.88:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: What is the syllabus for data 606 | Intent: Get_Course_info\n",
            "Awaiting valid feedback from user.\n",
            "INFO:     66.249.83.84:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: Yes | Intent: Feedback\n",
            "Feedback received and conversation history saved.\n",
            "INFO:     66.249.83.85:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: What is the syllabus for data 606 | Intent: Get_Course_info\n",
            "True matches criteria\n",
            "['DATA 606']\n",
            "Here are the course titles:  ['DATA 606 Capstone in Data Science']\n",
            "INFO:     66.249.83.84:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: Can you provide me the link for data 606 syllabus | Intent: Get_Course_info\n",
            "True matches criteria\n",
            "['DATA 606']\n",
            "Here are the course titles:  ['DATA 606 Capstone in Data Science']\n",
            "INFO:     66.249.83.72:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: How do I apply for GA | Intent: Get_General_info\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: What is the syllabus for data 606\n",
            "Assistant: | Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| 1    | Introduction to Agile Data Warehousing Project Management |\n",
            "| 2    | Team Formation and Project Pitch |\n",
            "| 3    | EDA Model Construction |\n",
            "| 4    | Execution and Interpretation |\n",
            "| 5    | GitHub Repository Setup |\n",
            "| 6    | Website Development for Project |\n",
            "| 7    | Presentation Preparation |\n",
            "| 8    | Final Project Presentations |\n",
            "| 9    | Course Reflection and Wrap-Up |\n",
            "\n",
            "| Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| 1    | Overview of Data Science Project Lifecycle |\n",
            "| 2    | Team Building and Project Planning |\n",
            "| 3    | Data Collection and Cleansing |\n",
            "| 4    | Method Selection and Implementation |\n",
            "| 5    | Model Evaluation and Accuracy Assessment |\n",
            "| 6    | Collaboration with Industry, Government, or Academic Partners |\n",
            "| 7    | Final Project Presentation Preparation |\n",
            "| 8    | Final Project Presentation and Report Writing |\n",
            "| 9    | Course Reflection and Wrap-Up |\n",
            "Human: Can you provide me the link for data 606 syllabus\n",
            "Assistant: | Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| 1    | Project Pitch: Each team presents their project idea, team members, and project plan |\n",
            "| 2    | EDA Model Construction: Teams start working on exploratory data analysis and model construction |\n",
            "| 3    | Execution and Interpretation: Teams execute their project plan and interpret the results |\n",
            "| 4    | Progress Presentations: Teams present their progress to the class and receive feedback |\n",
            "| 5    | Progress Presentations: Continued presentations and feedback sessions |\n",
            "| 6    | Final Presentations: Teams present their final project outcomes and findings |\n",
            "| 7    | Final Presentations: Continued final presentations and wrap-up of the course |\n",
            "\n",
            "| Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| Details not available |\n",
            "Follow Up Input: How do I apply for GA\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: You are a helpful assistant for students, here to provide accurate answers strictly based on the provided context.\n",
            "        Do not create or infer any information that isn’t explicitly in the context. If the answer cannot be found within the context, respond with a polite message indicating that additional information is needed and prompt the student to either rephrase their question or clarify. If applicable, you may suggest specific topics or terms that could help refine the search.\n",
            "        Context: The final selection for the fall semester is made in August and for the spring semester in January. Students who are chosen for our GGT positions will be notified accordingly.\n",
            "  HOW TO APPLY?\n",
            "Please fill out this form. Note that\n",
            "You will need to be logged in with your UMBC email account to have access to this form. If it says you don’t have permission, please log out from all your Gmail accounts and sign in to your UMBC email account only.\n",
            "Also, you will need to have pdf copies of your latest resume and current UMBC transcript as pdf files in your Google Drive folder!\n",
            "Once again, you will need to be done with DATA 601, 602, 603, and 604 before the semester you want to start working as a graduate tutor!\n",
            "\n",
            "Statement outlining your goals and expectations in the program. This also is an opportunity for you to further explain your background and qualifications for the program and provide any additional information about you or your experience which will help with the evaluation of your application.\n",
            "Current resume (When applying online, upload your resume to the graduate school application.)\n",
            "Transcript(s) from each college & university attended\n",
            "Local Students: Completed application including residency form (Residency form determines in-state tuition eligibility)\n",
            "International Students: TOEFL, IELTS or PTE test score\n",
            "Non-refundable application fee ($50 online)\n",
            "How do I apply?\n",
            "By submitting an online application. Here’re the specific steps:\n",
            "Go to the application website\n",
            "Select proposed program Data Science >> Data Science (PRST MPS)\n",
            "Choose the campus you want to study.\n",
            "Submit your statement of goals as an attachment in the “Academic Goals and Research Interests” section.\n",
            "\n",
            "Every semester, we hire a few MPS Data Science students as graduate graders/tutors (GGTs). In order to be considered for a GGT position, you need to complete Data 601, 602, 603, and 604 and formally apply through this page.\n",
            "A formal application through the link below is the only thing you need to be considered for a GGT position, provided that you fulfill all eligibility criteria. You do not need any recommendation from a faculty member for your application to be considered. Please note that sending personal emails to our faculty members including the directors will not enhance your chances for receiving a GGT position!\n",
            "\n",
            "Current resume (When applying online, upload your resume to the graduate school application.)\n",
            "Transcript(s) from each college & university attended\n",
            "2 reference letters\n",
            "International Students: TOEFL, IELTS, or PTE test score\n",
            "Non-refundable application fee ($50 online)\n",
            "How do I apply?\n",
            "By submitting an online application. Here’re the specific steps:\n",
            "Go to the application website\n",
            "Select proposed program Data Science >> Data Science (PRST MPS)\n",
            "Choose the campus you want to study. (Main campus is recommended for international students).\n",
            "Submit your statement of goals as an attachment in the “Academic Goals and Research Interests” section.\n",
            "Submit your resume.\n",
            "Even though there is a section for Financial Assistance, we do not offer any kind of assistantship for MPS students.\n",
            "Next -> Next -> Provide information about your references.\n",
            "Next -> Answer the questions.\n",
            "Review and submit.\n",
            "\n",
            "Login to your ISSS Portal \n",
            "Click on “Search Forms” in the top right corner of the page\n",
            "Choose the relevant request – Curricular Practical Training (CPT)\n",
            "Read the directions and complete all sections of the application\n",
            "Please note that CPT often requires enrollment in the Career Center’s “Internship Success Practicum (PRAC).”  Please upload the email confirmation of your enrollment to meet this requirement.\n",
            "NOTE: If you are using PRAC, do NOT submit your application until your PRAC is approved and you are able to upload your PRAC approval email.\n",
            "The application requires the support of your academic advisor.  Please follow the directions under the “Recommendations” section to invite your advisor to provide their support electronically.  For Graduate Students, you will need to do the process a second time to get your Graduate Program Director (GPD)’s approval as well.\n",
            "Only click submit after you have uploaded all requirements.\n",
            "        Student's Question: How do I apply for General Assembly?\n",
            "        Use the conversation history to provide a consistent response.\n",
            "        Conversation History: \n",
            "Human: What is the syllabus for data 606\n",
            "Assistant: | Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| 1    | Introduction to Agile Data Warehousing Project Management |\n",
            "| 2    | Team Formation and Project Pitch |\n",
            "| 3    | EDA Model Construction |\n",
            "| 4    | Execution and Interpretation |\n",
            "| 5    | GitHub Repository Setup |\n",
            "| 6    | Website Development for Project |\n",
            "| 7    | Presentation Preparation |\n",
            "| 8    | Final Project Presentations |\n",
            "| 9    | Course Reflection and Wrap-Up |\n",
            "\n",
            "| Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| 1    | Overview of Data Science Project Lifecycle |\n",
            "| 2    | Team Building and Project Planning |\n",
            "| 3    | Data Collection and Cleansing |\n",
            "| 4    | Method Selection and Implementation |\n",
            "| 5    | Model Evaluation and Accuracy Assessment |\n",
            "| 6    | Collaboration with Industry, Government, or Academic Partners |\n",
            "| 7    | Final Project Presentation Preparation |\n",
            "| 8    | Final Project Presentation and Report Writing |\n",
            "| 9    | Course Reflection and Wrap-Up |\n",
            "Human: Can you provide me the link for data 606 syllabus\n",
            "Assistant: | Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| 1    | Project Pitch: Each team presents their project idea, team members, and project plan |\n",
            "| 2    | EDA Model Construction: Teams start working on exploratory data analysis and model construction |\n",
            "| 3    | Execution and Interpretation: Teams execute their project plan and interpret the results |\n",
            "| 4    | Progress Presentations: Teams present their progress to the class and receive feedback |\n",
            "| 5    | Progress Presentations: Continued presentations and feedback sessions |\n",
            "| 6    | Final Presentations: Teams present their final project outcomes and findings |\n",
            "| 7    | Final Presentations: Continued final presentations and wrap-up of the course |\n",
            "\n",
            "| Week | Topic Description |\n",
            "|------|-------------------|\n",
            "| Details not available |\n",
            "        Example Response (when information is missing):\n",
            "        I couldn't find a direct answer in the provided information. Could you provide more details or rephrase your question? You might also consider specifying terms or topics to help refine the search.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "INFO:     66.249.83.73:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: How do I apply for GA/TA | Intent: Get_General_info\n",
            "Awaiting valid feedback from user.\n",
            "INFO:     66.249.83.71:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: no | Intent: Feedback\n",
            "Feedback received and conversation history saved.\n",
            "INFO:     66.249.83.71:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: How do I apply for GA/TA | Intent: Get_General_info\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: You are a helpful assistant for students, here to provide accurate answers strictly based on the provided context.\n",
            "        Do not create or infer any information that isn’t explicitly in the context. If the answer cannot be found within the context, respond with a polite message indicating that additional information is needed and prompt the student to either rephrase their question or clarify. If applicable, you may suggest specific topics or terms that could help refine the search.\n",
            "        Context: The final selection for the fall semester is made in August and for the spring semester in January. Students who are chosen for our GGT positions will be notified accordingly.\n",
            "  HOW TO APPLY?\n",
            "Please fill out this form. Note that\n",
            "You will need to be logged in with your UMBC email account to have access to this form. If it says you don’t have permission, please log out from all your Gmail accounts and sign in to your UMBC email account only.\n",
            "Also, you will need to have pdf copies of your latest resume and current UMBC transcript as pdf files in your Google Drive folder!\n",
            "Once again, you will need to be done with DATA 601, 602, 603, and 604 before the semester you want to start working as a graduate tutor!\n",
            "\n",
            "Every semester, we hire a few MPS Data Science students as graduate graders/tutors (GGTs). In order to be considered for a GGT position, you need to complete Data 601, 602, 603, and 604 and formally apply through this page.\n",
            "A formal application through the link below is the only thing you need to be considered for a GGT position, provided that you fulfill all eligibility criteria. You do not need any recommendation from a faculty member for your application to be considered. Please note that sending personal emails to our faculty members including the directors will not enhance your chances for receiving a GGT position!\n",
            "\n",
            "Login to your ISSS Portal \n",
            "Click on “Search Forms” in the top right corner of the page\n",
            "Choose the relevant request – Curricular Practical Training (CPT)\n",
            "Read the directions and complete all sections of the application\n",
            "Please note that CPT often requires enrollment in the Career Center’s “Internship Success Practicum (PRAC).”  Please upload the email confirmation of your enrollment to meet this requirement.\n",
            "NOTE: If you are using PRAC, do NOT submit your application until your PRAC is approved and you are able to upload your PRAC approval email.\n",
            "The application requires the support of your academic advisor.  Please follow the directions under the “Recommendations” section to invite your advisor to provide their support electronically.  For Graduate Students, you will need to do the process a second time to get your Graduate Program Director (GPD)’s approval as well.\n",
            "Only click submit after you have uploaded all requirements.\n",
            "\n",
            "Statement outlining your goals and expectations in the program. This also is an opportunity for you to further explain your background and qualifications for the program and provide any additional information about you or your experience which will help with the evaluation of your application.\n",
            "Current resume (When applying online, upload your resume to the graduate school application.)\n",
            "Transcript(s) from each college & university attended\n",
            "Local Students: Completed application including residency form (Residency form determines in-state tuition eligibility)\n",
            "International Students: TOEFL, IELTS or PTE test score\n",
            "Non-refundable application fee ($50 online)\n",
            "How do I apply?\n",
            "By submitting an online application. Here’re the specific steps:\n",
            "Go to the application website\n",
            "Select proposed program Data Science >> Data Science (PRST MPS)\n",
            "Choose the campus you want to study.\n",
            "Submit your statement of goals as an attachment in the “Academic Goals and Research Interests” section.\n",
            "\n",
            "Current resume (When applying online, upload your resume to the graduate school application.)\n",
            "Transcript(s) from each college & university attended\n",
            "2 reference letters\n",
            "International Students: TOEFL, IELTS, or PTE test score\n",
            "Non-refundable application fee ($50 online)\n",
            "How do I apply?\n",
            "By submitting an online application. Here’re the specific steps:\n",
            "Go to the application website\n",
            "Select proposed program Data Science >> Data Science (PRST MPS)\n",
            "Choose the campus you want to study. (Main campus is recommended for international students).\n",
            "Submit your statement of goals as an attachment in the “Academic Goals and Research Interests” section.\n",
            "Submit your resume.\n",
            "Even though there is a section for Financial Assistance, we do not offer any kind of assistantship for MPS students.\n",
            "Next -> Next -> Provide information about your references.\n",
            "Next -> Answer the questions.\n",
            "Review and submit.\n",
            "        Student's Question: How do I apply for GA/TA\n",
            "        Use the conversation history to provide a consistent response.\n",
            "        Conversation History: \n",
            "        Example Response (when information is missing):\n",
            "        I couldn't find a direct answer in the provided information. Could you provide more details or rephrase your question? You might also consider specifying terms or topics to help refine the search.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "INFO:     66.249.83.71:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: How do I apply for GGT | Intent: Get_General_info\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: How do I apply for GA/TA\n",
            "Assistant: I couldn't find specific information on applying for Graduate Assistantship (GA) or Teaching Assistantship (TA) positions in the given context. Could you please provide more details or clarify your question? It would be helpful to know if there are specific requirements or steps you are referring to in order to assist you better.\n",
            "Follow Up Input: How do I apply for GGT\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: You are a helpful assistant for students, here to provide accurate answers strictly based on the provided context.\n",
            "        Do not create or infer any information that isn’t explicitly in the context. If the answer cannot be found within the context, respond with a polite message indicating that additional information is needed and prompt the student to either rephrase their question or clarify. If applicable, you may suggest specific topics or terms that could help refine the search.\n",
            "        Context: Every semester, we hire a few MPS Data Science students as graduate graders/tutors (GGTs). In order to be considered for a GGT position, you need to complete Data 601, 602, 603, and 604 and formally apply through this page.\n",
            "A formal application through the link below is the only thing you need to be considered for a GGT position, provided that you fulfill all eligibility criteria. You do not need any recommendation from a faculty member for your application to be considered. Please note that sending personal emails to our faculty members including the directors will not enhance your chances for receiving a GGT position!\n",
            "\n",
            "The eligibility conditions stated above are the necessary conditions, but are not sufficient. This means that there is no guarantee to receive a GGT position even if you fulfill all the criteria! We have only a very limited number of positions and the number of applications we receive typically far exceeds the number of available positions. We do our best to conduct the selection process for the GGT positions as fair as possible. For this reason, we will not entertain any personal requests in the selection process.\n",
            "Note that new students are NOT eligible to apply for GGT positions.\n",
            "If you are going to have an internship next semester, then please do not apply for a GGT position.\n",
            "If the next semester is going to be your last semester at UMBC and if you are going to take only one class, then please do not apply for GGT. Having a full-time internship or job-search should be your number one priority.\n",
            "\n",
            "The final selection for the fall semester is made in August and for the spring semester in January. Students who are chosen for our GGT positions will be notified accordingly.\n",
            "  HOW TO APPLY?\n",
            "Please fill out this form. Note that\n",
            "You will need to be logged in with your UMBC email account to have access to this form. If it says you don’t have permission, please log out from all your Gmail accounts and sign in to your UMBC email account only.\n",
            "Also, you will need to have pdf copies of your latest resume and current UMBC transcript as pdf files in your Google Drive folder!\n",
            "Once again, you will need to be done with DATA 601, 602, 603, and 604 before the semester you want to start working as a graduate tutor!\n",
            "\n",
            "Login to your ISSS Portal \n",
            "Click on “Search Forms” in the top right corner of the page\n",
            "Choose the relevant request – Curricular Practical Training (CPT)\n",
            "Read the directions and complete all sections of the application\n",
            "Please note that CPT often requires enrollment in the Career Center’s “Internship Success Practicum (PRAC).”  Please upload the email confirmation of your enrollment to meet this requirement.\n",
            "NOTE: If you are using PRAC, do NOT submit your application until your PRAC is approved and you are able to upload your PRAC approval email.\n",
            "The application requires the support of your academic advisor.  Please follow the directions under the “Recommendations” section to invite your advisor to provide their support electronically.  For Graduate Students, you will need to do the process a second time to get your Graduate Program Director (GPD)’s approval as well.\n",
            "Only click submit after you have uploaded all requirements.\n",
            "\n",
            "Statement outlining your goals and expectations in the program. This also is an opportunity for you to further explain your background and qualifications for the program and provide any additional information about you or your experience which will help with the evaluation of your application.\n",
            "Current resume (When applying online, upload your resume to the graduate school application.)\n",
            "Transcript(s) from each college & university attended\n",
            "Local Students: Completed application including residency form (Residency form determines in-state tuition eligibility)\n",
            "International Students: TOEFL, IELTS or PTE test score\n",
            "Non-refundable application fee ($50 online)\n",
            "How do I apply?\n",
            "By submitting an online application. Here’re the specific steps:\n",
            "Go to the application website\n",
            "Select proposed program Data Science >> Data Science (PRST MPS)\n",
            "Choose the campus you want to study.\n",
            "Submit your statement of goals as an attachment in the “Academic Goals and Research Interests” section.\n",
            "        Student's Question: How do I apply for GGT?\n",
            "        Use the conversation history to provide a consistent response.\n",
            "        Conversation History: \n",
            "Human: How do I apply for GA/TA\n",
            "Assistant: I couldn't find specific information on applying for Graduate Assistantship (GA) or Teaching Assistantship (TA) positions in the given context. Could you please provide more details or clarify your question? It would be helpful to know if there are specific requirements or steps you are referring to in order to assist you better.\n",
            "        Example Response (when information is missing):\n",
            "        I couldn't find a direct answer in the provided information. Could you provide more details or rephrase your question? You might also consider specifying terms or topics to help refine the search.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "INFO:     66.249.83.73:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: How Can I apply for OPT | Intent: Get_CPT_OPT_info\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: How do I apply for GA/TA\n",
            "Assistant: I couldn't find specific information on applying for Graduate Assistantship (GA) or Teaching Assistantship (TA) positions in the given context. Could you please provide more details or clarify your question? It would be helpful to know if there are specific requirements or steps you are referring to in order to assist you better.\n",
            "Human: How do I apply for GGT\n",
            "Assistant: I couldn't find specific information on applying for a GGT (Graduate Grader/Tutor) position in the context provided. It seems that the application process for GGT positions is separate from the general application process mentioned for other programs. To apply for a GGT position, you need to complete Data 601, 602, 603, and 604 and then formally apply through the provided page. The final selection for the fall semester is made in August and for the spring semester in January. If you fulfill the eligibility criteria, you should follow the instructions given on the page for applying.\n",
            "Follow Up Input: How Can I apply for OPT\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: You need to answer the user's question about CPT or OPT information based on the given context only.\n",
            "        Give friendly responses.\n",
            "        Use the conversation history to provide a consistent response.\n",
            "        Conversation History: \n",
            "Human: How do I apply for GA/TA\n",
            "Assistant: I couldn't find specific information on applying for Graduate Assistantship (GA) or Teaching Assistantship (TA) positions in the given context. Could you please provide more details or clarify your question? It would be helpful to know if there are specific requirements or steps you are referring to in order to assist you better.\n",
            "Human: How do I apply for GGT\n",
            "Assistant: I couldn't find specific information on applying for a GGT (Graduate Grader/Tutor) position in the context provided. It seems that the application process for GGT positions is separate from the general application process mentioned for other programs. To apply for a GGT position, you need to complete Data 601, 602, 603, and 604 and then formally apply through the provided page. The final selection for the fall semester is made in August and for the spring semester in January. If you fulfill the eligibility criteria, you should follow the instructions given on the page for applying.\n",
            "        Context: Second, students will need to upload a draft I-765. Students should download a draft I-765 by clicking “View Draft Snapshot” in their online USCIS account. Students who upload a draft I-765 with the incorrect format will need to re-upload it in the correct format.\n",
            "\n",
            "ISSS will review each student’s OPT request and send an email if anything is missing. Once approved, students will receive an I-20 with the OPT recommendation listed on the second page. The I-20 should list “OPT Requested” on the second page, with requested start and end dates. Please contact us if anything needs to be corrected.\n",
            "\n",
            "To do’s:\n",
            "\n",
            "Watch a previous OPT Workshop presentation (requires myUMBC login) and review the slides\n",
            "Download a draft I-765 application\n",
            "Submit a complete OPT request in the ISSS Portal\n",
            "\n",
            "Remember: you do not need a job offer before applying!\n",
            "\n",
            " \n",
            "\n",
            "Step 2: Submit I-765 OPT Application to USCIS\n",
            "\n",
            "OPT Checklist\n",
            "\n",
            "SEVP Portal Help\n",
            "\n",
            " \n",
            "\n",
            "Read This First\n",
            "\n",
            "OPT follows federal and school regulations:\n",
            "\n",
            "OPT must be related to the student’s major program of study.\n",
            "Students must receive an OPT I-20 from the ISSS office before submitting their application to USCIS.\n",
            "OPT is granted only once per education level.\n",
            "Once approved by USCIS:\n",
            "Students are approved for 1 year of work authorization.\n",
            "Students cannot begin working before the start date on their Employment Authorization Document (EAD) card.\n",
            "Students must work a combined total of at least 20 hours/week.\n",
            "Positions can be unpaid/paid and with multiple employers.\n",
            "\n",
            "Students should plan ahead and begin the application process with the ISSS office as early as possible.\n",
            "\n",
            "Eligibility\n",
            "\n",
            "To be eligible for OPT, students must meet following criteria:\n",
            "\n",
            "Step 2: Submit I-765 OPT Application to USCIS\n",
            "\n",
            "The ISSS office will review each OPT request and email the student about any potential edits students should change on their draft I-765. Students will also be able to view their OPT I-20 in their request. Students must print out and sign their OPT I-20 with ink. Submitting an application without a signature will likely result in a denial. Finally, students must upload all required documentation and submit their I-765 application using the USCIS online application system. The current fee for submitting an I-765 is $410. The fee is increasing to $470 and will go into effect on April 1, 2024.\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "USCIS Online Application Step-by-Step Guide\n",
            "OPT Checklist\n",
            "\n",
            "BEFORE YOU SUBMIT: Double check to see if “OPT Requested” with the requested start and end dates is on the second page of your I-20! If you submit your OPT application to USCIS without this OPT I-20, it will be automatically denied!\n",
            "\n",
            " \n",
            "\n",
            "Step 3: Track Case Status\n",
            "\n",
            "Eligibility\n",
            "\n",
            "To be eligible for OPT, students must meet following criteria:\n",
            "\n",
            "Currently enrolled at UMBC full time with active F-1 status\n",
            "Completed two consecutive academic semesters (fall and spring) in the US\n",
            "Completed all program requirements for degree\n",
            "Exceptions for graduate students who only have a thesis/dissertation remaining\n",
            "Have not been previously granted OPT at the current level of study\n",
            "Have not been approved for 12 months or more of full time Curricular Practical Training (CPT)\n",
            "\n",
            " \n",
            "\n",
            "Application Process\n",
            "\n",
            "Students must first receive a special OPT I-20 from the ISSS office before submitting their OPT application to USCIS. Applications submitted to USCIS without an OPT-specific I-20 will be denied. USCIS processing times can take up to three months or more, so students should plan ahead and apply early. Contact our office about any concerns or questions.\n",
            "\n",
            " \n",
            "\n",
            "Application Submission Period\n",
            "\n",
            "Do I need a job offer before applying for OPT?\n",
            "How do I select an OPT start date?\n",
            "I am a graduate student who only has a thesis or dissertation left. Am I eligible?\n",
            "My OPT application is still pending. When should I expect a response from USCIS?\n",
            "I have not received my EAD card yet. What do I do?\n",
            "I lost my EAD card.\n",
            "Can I take a course while on OPT?\n",
            "How many unemployment days do I have?\n",
            "How do I enter my employer info into the SEVP Portal?\n",
            "I am having trouble logging into my SEVP Portal account.\n",
            "I entered my employer information in my SEVP Portal. Do I need to follow-up with ISSS?\n",
            "        Question: How can I apply for OPT?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "INFO:     66.249.83.73:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: Yes | Intent: Feedback\n",
            "Feedback received and conversation history saved.\n",
            "INFO:     66.249.83.87:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: Are there any working opportunities in campus | Intent: Get_Research_info\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: You need to answer the user's question about research information. Please dont assume answer only based on the context given\n",
            "        Use the conversation history to provide a consistent response.\n",
            "        Conversation History: \n",
            "        Context: Communications and Photonics\n",
            "Topics: Cognitive Radio,  Nonlinear and Integrated Optics, Optical Fibers, Wireless Communications and Networking\n",
            "Faculty: Gary Carter, Fow-Sen Choa, Anthony Johnson, Seung-Jun Kim, Curtis Menyuk, Dmitri Perkins, Ergun Simsek, Li Yan, Mohamed Younis\n",
            "Computer Architecture and Hardware Systems\n",
            "Topics: Hardware Security, Low-power IC Design, Multicore Systems, Neuromorphic Computing, VLSI Design/Test\n",
            "Faculty: Riadul Islam, Naghmeh Karimi, Chenchen Liu, Dhananjay Phatak, Ryan Robucci\n",
            "Cyber-Physical Systems\n",
            "Topics: IoT, Networking, Network Protocols and Management, Network Security, Secure Communication, Smart Power Grids\n",
            "Faculty: Nilanjan Banerjee, Riadul Islam, Anupam Joshi, Naghmeh Karimi, Seung-Jun Kim, Dong Li, Dmitri Perkins, Ryan Robucci, Deepinder Sidhu, Mohamed Younis, Roberto Yus\n",
            "Graphics and Visualization\n",
            "Topics: Character Animation, Computer Graphics, Scientific/Data Visualization\n",
            "Faculty: Adam Bargteil, Don Engel, Mark Olano, Rebecca Williams\n",
            "AI, Machine Learning, and Signal Processing\n",
            "Topics: AI, Data Analytics, Knowledge Representation, Machine Learning, Matrix and Tensor Factorizations, Natural Language Processing, Computer Vision, Robotics, Statistical Signal Processing\n",
            "Faculty: Tulay Adali, Justin Brooks, Chein-I Chang, Keke Chen, Sanorita Dey, Don Engel,  Frank Ferraro, Tim Finin, Tejas Gokhale, Riadul Islam, Manas Gaur, Konstantinos Kalpakis, Seung-Jun Kim, Dong Li, Lara Martin, Cynthia Matuszek, Charles Nicholas, Tim Oates, Ramana Vinjamuri, Rebecca Williams\n",
            "Security and Privacy\n",
            "Topics: Computer Security, Cryptography, Cybersecurity, Malware Analysis, Protocols, Secure Voting\n",
            "Faculty: Nilanjan Banerjee, Keke Chen, Tim Finin, Richard Forno,  Anupam Joshi, Naghmeh Karimi, Charles Nicholas, Dhananjay Phatak, Alan Sherman, Deepinder Sidhu, Mohamed Younis, Roberto Yus\n",
            "Quantum Computing/Theory and Algorithms\n",
            "Topics: Computational Complexity Theory, Quantum Computation, Quantum Information, Scientific and Engineering Computation\n",
            "Faculty: Richard Chang, Milt Halem, Sam Lomonaco, Curtis Menyuk, Yaacov Yesha\n",
            "\n",
            "Research Centers and Laboratories\n",
            "Computer Science\n",
            "CDL – Cyber Defense Lab\n",
            "\n",
            "Director: Dr. Alan T. Sherman\n",
            "Office No. : ITE 224, Lab No. : ITE 228\n",
            "\n",
            "The UMBC Cyber Defense Lab (CDL) is a place where students, faculty, and affiliates carry out cybersecurity research. Current projects include high-integrity voting, protocol analysis, and cybersecurity education.\n",
            "\n",
            "CORAL – Cognition Robotics and Learning Lab\n",
            "\n",
            "Director: Dr. Tim Oates\n",
            "Office No. : ITE 336, Lab No. : ITE 361\n",
            "\n",
            "Research in topics related to machine and human intelligence, including machine vision, natural language processing, and reinforcement learning. The long-term goal is to understand how machines can match the human developmental trajectory from sensors to symbols to semantics. Current projects include sample efficient reinforcement learning for the real world, safe artificial intelligence, graph neural networks for anomaly detection in learned models, and multi-modal learning from images and text.\n",
            "\n",
            "CVG – Cognitive Vision Group\n",
            "\n",
            "Director: Dr. Tejas Gokhale\n",
            "Office No.: ITE 214, Lab No.: ITE 368\n",
            "\n",
            "The Cognitive Vision Group works on the conceptual characterization of visual scenes, broadly in the areas of computational perception, learning, and reasoning. Areas of innovation include visual understanding in the absence of complete information; adapting and generalizing to new concepts, contexts, domains, environments, and tasks; extrapolation across space and time; interpreting and predicting behavior; acquisition and communication of visual knowledge from/with/to other agents and humans.\n",
            "\n",
            "DAMS – Data Management and Semantics\n",
            "\n",
            "Director: Dr. Roberto Yus\n",
            "Office No. : ITE 342, Lab No. : ITE 230\n",
            "\n",
            "he UMBC DAMS Research Group focuses on four main areas of research: Data Management, AI, Privacy, and the Internet of Things. We deal with research challenges in bridging the gap that exists between raw data (e.g., data captured by sensors) and semantically meaningful data that is easily understood by people (e.g., inferences extracted from sensor observations). We incorporate semantics and privacy-awareness to data management to design smarter and more responsible systems. Also, we develop prototypes of the approaches/systems designed as part of the research tasks and deploy them in the real world.\n",
            "\n",
            "DREAM – Discovery, Research, and Experimental Analysis of Malware Lab\n",
            "\n",
            "Director: Dr. Charles Nicholas\n",
            "Office No. : ITE 356, Lab No. : ITE 366\n",
            "\n",
            "The DREAM lab looks at ways of applying machine learning to cybersecurity, and malware analysis in particular. Recent projects involve using tensor decomposition and innovative measures of string similarity to solve practical problems. The lab is also home to UMBC’s very active cyberdefense competition team, the ‘CyberDawgs’\n",
            "\n",
            "Ebiquity Research Laboratory\n",
            "\n",
            "Director: Dr. Anupam Joshi\n",
            "Office No. : ITE 328, Lab No. : ITE 332\n",
            "\n",
            "Director: Dr. Tim Finin\n",
            "Office No. : ITE 329, Lab No. : ITE 332, ITE 338\n",
            "\n",
            "Building intelligent systems in open, heterogeneous, dynamic, distributed environments. Research topics include the semantic web, information extraction, mobile computing, privacy, and security.\n",
            "\n",
            "ESNET – Embedded Systems and Networks Laboratory\n",
            "\n",
            "Director: Dr. Mohamed Younis\n",
            "Office No. : ITE 325 G, Lab No. : ITE 391\n",
            "\n",
            "Design and management of wireless sensor networks, network architecture and protocols, underwater communication, MAC and routing protocols for ad-hoc and sensor networks, energy-aware system design, secure communication, fault tolerance, topology management, and applications of sensor and actuator networks.\n",
            "\n",
            "FSI – Future Sensing and Interaction Lab\n",
            "\n",
            "Director: Dr. Dong Li\n",
            "Office No. : ITE 355, Lab No. : ITE 230\n",
            "\n",
            "The Future Sensing and Interaction Lab is dedicated to advancing the fields of mobile, wearable, and ubiquitous computing. The lab’s core mission is to design and develop innovative sensing systems that address critical societal challenges, particularly in healthcare, human-computer interaction, and environmental sustainability. Our research integrates expertise in mobile computing, wireless and wearable sensing, multi-modal sensing, smart health technologies, and AI for IoT. We are committed to creating cutting-edge solutions that bridge the gap between advanced technological developments and real-world applications. At the FSI Lab, we envision a future where technology plays a transformative role in promoting a more equitable and sustainable world.\n",
            "\n",
            "IRAL – Interactive Robotics and Language Laboratory\n",
            "\n",
            "Director: Dr. Cynthia Matuszek\n",
            "Office No. : ITE 331, Lab No. : ITE 343\n",
            "\n",
            "Research in robotics, human-robot interaction, and grounded language understanding, bringing together robotics, natural language processing, and statistical learning approaches to build advanced intelligent agents that can interact robustly with non-specialists.\n",
            "\n",
            "KAI² – Knowledge-infused AI and Inference\n",
            "\n",
            "Director: Dr. Manas Gaur\n",
            "Office No. : ITE 337, Lab No. : ITE 367\n",
            "\n",
            "KAI² believes in the integration and uplifting of AI with human knowledge representable in different forms: Structural Knowledge Graphs, Flattened Lexicons, Process Knowledge in Questionnaires, and Commonsense in General-purpose unstructured content, to design human-centered systems and applications for sensitive domains. Furthermore, we want to make the next-generation neuro-symbolic AI approach inspired by human’s ability to combine data and knowledge to induce Explainable, Interpretable, and Safety aspects in statistical AI.\n",
            "\n",
            "LARA Lab\n",
            "\n",
            "Director: Dr. Lara J. Martin\n",
            "Office No. : ITE 216, Lab No. : ITE 368\n",
            "\n",
            "In the LARA Lab, we look at using and improving language tools to make better, human-centered artificial intelligence (AI) by looking at how people communicate and creating computer-supported human communication tools. We pull together techniques from natural language processing (NLP), cognitive science, and AI to create agents that tell stories and play Dungeons & Dragons, speak expressively, and aid accessibility in human-human communication.\n",
            "\n",
            "Social Intelligence Lab\n",
            "\n",
            "Director: Dr. Sanorita Dey\n",
            "Office No. : ITE 357, Lab No. : ITE 339\n",
            "\n",
            "In the Social Intelligence Lab, we explore a variety of social computing topics. Our primary goal is to understand how people engage with complex systems and to design user-centric systems and platforms that address the perceptions of our target audience. Currently, we are focusing on areas such as accessible health monitoring, equitable and sustainable STEM education, and the application of large language models to foster ethical and responsible social opinions. Students in our lab publish their research in prestigious international conferences, including CHI, CSCW, GROUP, IUI, and iTICSE.\n",
            "\n",
            "TAIC – Trustworthy and Intelligent Computing\n",
            "\n",
            "Director: Keke Chen\n",
            "Office No. : ITE 360, Lab No. : ITE 345\n",
            "\n",
            "The TAIC lab studies security and privacy issues with AI and collaborative systems, confidential computing, and applications of AI in science.\n",
            "\n",
            "VANGOGH – Visualization, Animation, Non-Photorealistic Graphics, Object Modeling, and Graphics Hardware\n",
            "\n",
            "Director: Dr. Adam Bargteil\n",
            "Office No. : ITE 341, Lab No. : ITE 365\n",
            "\n",
            "Director: Dr. Marc Olano\n",
            "Office No. : ITE 354, Lab No. : ITE 352, 365\n",
            "\n",
            "The VANGOGH lab covers a range of research in computer graphics and animation. Computer graphics research focuses on real-time approaches using graphics hardware, particularly in areas of visual appearance, data visualization, and techniques applicable to computer games. Animation research focuses on natural phenomena, including physics-based techniques, numerical methods, and machine learning.\n",
            "\n",
            "Vinjamuri Lab\n",
            "\n",
            "Director: Dr. Ramana Vinjamuri\n",
            "Office No. : ITE 301, Lab No. : ITE 376\n",
            "\n",
            "Our lab studies Brain-Machine Interfaces (BMIs) that control upper-limb prostheses. In particular, we are interested in how the brain controls complex hand movements. The human hand has about 30 dimensions in contrast to a human arm with only 7 dimensions. BMIs that control human arms have already been demonstrated with decent accuracy. What type of interface is needed to Extend Brain-Machine Interface control from 7 to 37 dimensions forms the central topic of our research. Our lab contains a mix of current Graduate, Undergraduate, and Highschool Students along with a range of collaborators from multiple industries. Our range of publications dating back to 2014 includes multiple Patents, Articles, Conference Appearances, and more. Our work has been recognized through many Showcases, Grants, and Awards alongside our students who continue to impress.\n",
            "\n",
            "Computer Engineering\n",
            "ECLIPSE Cluster\n",
            "\n",
            "Director: Dr. Nilanjan Banerjee\n",
            "Office No. : ITE 362, Lab No. : ITE 351\n",
            "\n",
            "Director: Dr. Ryan Robucci\n",
            "Office No. : ITE 319, Lab No. : ITE 317\n",
            "\n",
            "The ECLIPSE cluster comprises groups with shared laboratories, projects, and students: the Mobile, Pervasive, & Sensor Systems Laboratory led by Dr. Nilanjan Banerjee, and the Covail Analog & Digital Systems Research Laboratory, led by Dr. Ryan Robucci\n",
            "\n",
            "ESNET – Embedded Systems and Networks Laboratory\n",
            "\n",
            "Director: Dr. Mohamed Younis\n",
            "Office No. : ITE 325 G, Lab No. : ITE 391\n",
            "\n",
            "Design and management of wireless sensor networks, network architecture and protocols, underwater communication, MAC and routing protocols for ad-hoc and sensor networks, energy-aware system design, secure communication, fault tolerance, topology management, and applications of sensor and actuator networks.\n",
            "\n",
            "SECRETS – SECure, REliable, and Trusted Systems\n",
            "\n",
            "Director: Dr. Naghmeh Karimi\n",
            "Office No. : ITE 314, Lab No. : ITE 210\n",
            "\n",
            "Our focus is primarily on the design, security, trustworthiness, reliability, and testability of electronic chips, particularly digital circuits. We concentrate on Hardware Security and Design-for-Trust, Fault Tolerance and Design-for-Reliability, Hardware Testing and Design-for-Testability, Machine Learning for security applications, the security of machine learning accelerators, and the design of VLSI circuits.\n",
            "\n",
            "Additionally, to ensure long-lasting security for cryptographic devices against physical attacks (such as side-channel analysis and fault injection), our lab develops countermeasures that remain effective as the device ages.\n",
            "\n",
            "We also focus on ensuring data integrity within IoT frameworks and protecting them against impersonation, replay, and other conventional attacks by developing lightweight authentication schemes. Furthermore, we design security protocols for the safe and secure transmission of data between patients’ wearable or implanted devices and healthcare providers.\n",
            "\n",
            "VLSI-SOC Group\n",
            "\n",
            "Director: Dr. Riadul Islam\n",
            "Office No. : ITE 316, Lab No. : ITE 313\n",
            "\n",
            "The primary research areas include Electronic Design and Automation, Brain-inspired computing, Neural network architecture exploration, Autonomous driving and CAN security, digital, analog, and mixed-signal CMOS ICs/SOCs for a variety of applications, Verification and testing techniques, CAD tools for design and analysis of microprocessors and FPGAs, as well as interdisciplinary research projects.\n",
            "\n",
            "Electrical Engineering\n",
            "CASPR – Center for Advanced Studies in Photonics Research\n",
            "\n",
            "Director: Dr. Anthony Johnson\n",
            "Office No. : TRC 029, Lab No. : TRC 027\n",
            "\n",
            "Advanced photonics research and technology development in optical communications, optical sensing and devices, nanophotonics, biophotonics, and quantum optics.\n",
            "\n",
            "Choa’s Lab\n",
            "\n",
            "Director: Dr. Fow-Sen Choa\n",
            "Office No. : ITE 303, TRC 274, Lab No. : TRC 018, 151, 153, 155, 156, 159, 291, 292, 293\n",
            "\n",
            "The lab is developing novel transcranial magnetic stimulation coils for multisite brain stimulations, extracting brain signals with designed experiments using EEG tools, studying brain dynamics and neural disorders from analyzing fMRI scanned data sets, and building human level intelligent systems through neural network architecture design and modelling. We also continue our research on design, growth and fabrication of photonic and nano-materials and devices including single photon detectors, photonic integration of tunable lasers and detector, mid-IR devices and arrays, meta-materials, phase changing materials, neuromorphic and neural computing devices for AI chips.\n",
            "\n",
            "Computational Photonics Laboratory\n",
            "\n",
            "Director: Dr. Curtis Menyuk\n",
            "Office No. : ITE 304, Lab No. : TRC 200, 201, 202, 203, 204, 205\n",
            "\n",
            "Assistant Director: Dr. Ergun Simsek\n",
            "Office No. : ITE 325 K, Lab No. : TRC 201 B\n",
            "\n",
            "Computational and theoretical studies of nonlinear optics, RF photonics, and frequency combs. We investigate nonlinear effects in optical fibers including soliton generation and transmission, supercontinuum generation, and four wave mixing. We study frequency comb generation in fiber lasers and microresonators and the noise processes that limit the performance of these devices and the overall system performance. We also study photodetectors, sensors, motheye surfaces, and other components that play an important role in photonic transmission and RF photonics. We use modern machine learning algorithms to optimize the performance of the RF-photonic devices and systems as well as the frequency comb systems that we investigate.\n",
            "\n",
            "MLSP-Lab – Machine Learning for Signal Processing Laboratory\n",
            "\n",
            "Director: Dr. Tulay Adali\n",
            "Office No. : ITE 324, Lab No. : ITE 363\n",
            "\n",
            "Our focus is the development of theory and tools for processing of signals that arise in today’s growing array of different applications and pose challenges for traditional signal processing techniques. We bring in techniques from statistical and adaptive signal processing as well as machine learning to develop effective methods to address challenges in a wide array of applications with a focus on medical image analysis and fusion.\n",
            "\n",
            "Remote Sensing Signal and Image Processing Laboratory\n",
            "\n",
            "Director: Dr. Chein-i Chang\n",
            "Office No. : ITE 310, Lab No. : ITE 370\n",
            "\n",
            "Research on remote sensing, signal and image processing, specifically, hyperspectral imaging, medical imaging, and automatic target recognition.\n",
            "\n",
            "Helena Mentis demonstrates tools that she uses in her HCI lab. Photo by Marlayna Demond ’11 for UMBC.\n",
            "\n",
            "There are many research labs and centers at UMBC that are focused on artificial intelligence or use AI technologies in their projects. These labs and centers are associated with the UMBC AI Center and are part of departments in all of UMBC’s Colleges.\n",
            "\n",
            "ATOMS Lab\n",
            "\n",
            "The AI & Theory-Oriented Molecular Science Lab is headed by Tyler Josephson in CBEE. Chemistry’s fundamental building are atoms; from their interactions emerge molecules, materials, and their properties. In logic, basic assumptions are also called atoms; proofs, lemmas, and theorems are derived from these. The ATOMS Lab brings together chemical engineers, computer scientists, and mathematicians to equip computers to reason about and discover theories in molecular science.\n",
            "\n",
            "Big Data Analytics Lab\n",
            "\n",
            "The Big Data Analytics Lab is led by Jianwu Wang in Information Systems and studies different aspects of big data analytics, including scalable causality analytics, scalable data aggregation, and anomaly detection, with current applications focusing on climate and manufacturing. We integrate techniques in distributed computing, data mining, and machine learning and work with academic and industry collaborators to achieve multidisciplinary research and social impacts.\n",
            "\n",
            "Causal AI Lab Lab\n",
            "\n",
            "Headed by Md Osman Gani, the CAIL lab studies causal inference, machine learning, and AI methods to contribute to a deeper understanding of the cause and context in data-intensive healthcare and ubiquitous computing environments. It’s work is collaborative and interdisciplinary and focuses on societal impacts with applications in healthcare, pervasive computing, rehabilitation engineering, occupational science, and more.\n",
            "\n",
            "Computational Mechanics Laboratory\n",
            "\n",
            "Professor MeIlin Yu’s Computational Mechanics Lab works on computational fluid dynamics, scientific machine learning, and high-performance computing. A current project, for example, uses reinforcement learning to develop computational fluid dynamics algorithms for large eddy simulation of turbulent flows.\n",
            "\n",
            "Center for Realtime Distributed Sensing and Autonomy\n",
            "\n",
            "The Center for Realtime Distributed Sensing and Autonomy (CARDS) was established in 2021 to develop cutting-edge technologies towards the betterment of society and field robotics. A Project funded by the Army Research Laboratory collaborated with the University of Maryland College Park, Bowie State University, and the Army Research Laboratory.\n",
            "\n",
            "Computing Compass Lab\n",
            "\n",
            "Prof. Chenchen Liu leads the Computing Compas Lab, which develops novel computing paradigms for high-performance intelligence computing and explores innovations in AI’s algorithm, architecture, system, and circuit designs. Its research topics cover novel computer architecture and hardware for AI, neuromorphic computing, deep learning, edge computing, and VLSI design with emerging technologies.\n",
            "\n",
            "Center for Research in Emergent Manufacturing\n",
            "\n",
            "Prof. Nilanjan Banerjee leads the Center for Research in Emergent Manufacturing which does research on Digital Manufacturing, incuding developing smart and secure cyber-physical manufacturing systems and supply chains.\n",
            "\n",
            "Data Management & Semantics Group\n",
            "\n",
            "DAMS, led by Roberto Yus, focuses on four areas of research: Data Management, AI, Privacy, and the Internet of Things. It deals with the challenges in bridging the gap between raw data (e.g., from sensors) and semantically meaningful data easily understood by people (e.g., inferences extracted from sensor data). it incorporates semantics and privacy awareness into data management to design smarter and more responsible systems, develop prototypes and deploys them in the real world.\n",
            "\n",
            "Dream Lab\n",
            "\n",
            "The DREAM lab led by Charles Nicholas looks at ways of applying machine learning and AI to cybersecurity, and malware analysis in particular. Recent projects involve using tensor decomposition and innovative measures of string similarity to solve practical problems. The lab is also home to UMBC’s very active cyber defense competition team, the ‘CyberDawgs’\n",
            "\n",
            "Ebiquity Research Group\n",
            "\n",
            "The Ebiquity Research Group consists of faculty and students from the CSEE and IS departments. Its research covers the application of AI to many areas, including natural language understanding, information extraction from text, mobile and pervasive computing, knowledge representation and reasoning, knowledge graphs, multi-agent systems, privacy, and cybersecurity.\n",
            "\n",
            "Estimation, Control & Learning Laboratory\n",
            "\n",
            "ECCL research is focused on developing data-driven, learning-based control and estimation techniques for mechanical and aerospace engineering problems. We use tools from linear and nonlinear system theory, linear and nonlinear control theory, optimization, and learning theory to design and develop novel algorithms for control and estimation problems in complex dynamic systems, including applications in robotics, autonomous systems, and UAVs.\n",
            "\n",
            "Informatics for Human Flourishing Lab\n",
            "\n",
            "The Informatics for Human Flourishing Lab works to create data-enabled human-centered technology and systems that promote human flourishing. It explores the fundamental data analytics/machine learning/AI methods that could solve practical problems, complemented by human-centered approaches using a mixture of quantitative and qualitative methods.\n",
            "\n",
            "Interactive Robotics and Language Lab\n",
            "\n",
            "IRAL is led by Cynthia Matuszek. It studies robotics and natural language processing to develop robots that everyday people can talk to, telling them to do tasks or about the world around them. This grounded language acquisition approach supports the goal of building robots that can perform tasks in noisy, real-world environments instead of being preemptively programmed to handle a fixed set of predetermined tasks.\n",
            "\n",
            "Knowledge, Analytics, Cognitive, and Cloud Computing lab\n",
            "\n",
            "The KnACC lab is led by Karuna Joshi from the Information Systems department and aims to address challenging issues at the intersection of Data Science and Cloud Computing.\n",
            "\n",
            "KAI² – Knowledge-infused AI and Inference\n",
            "\n",
            "KAI² is led by Manas Gaur and works on the integration and uplifting of AI with human knowledge representable in different forms: Structural Knowledge Graphs, Flattened Lexicons, Process Knowledge in Questionnaires, and Commonsense in General-purpose unstructured content, to design human-centered systems and applications for sensitive domains. It aims to make the next-generation neuro-symbolic AI approach inspired by humans’ ability to combine data and knowledge to induce Explainable, Interpretable, and Safety aspects in statistical AI.\n",
            "\n",
            "Lab for Healthcare Engineering\n",
            "\n",
            "The Laboratory for Healthcare Engineering is headed by Dr. Muhammad Ali Yousuf. It focuses on machine learning and AI applied to the analysis of health insurance data, medical image processing using DeepLearning and AI, the ethics of Artificial Intelligence in general and in relation to medical data and devices, and generative AI in the classroom.\n",
            "\n",
            "Language, Aid, and Representation AI Lab\n",
            "\n",
            "Professor Lara Martin leads the Language, Aid, and Representation AI Lab. Its research focuses on human-centered artificial intelligence and natural language processing applications. Recent work has included automated story generation, augmentative and alternative communication tools, AI for tabletop role-playing games, speech processing, and affective computing.\n",
            "\n",
            "The Latent Lab\n",
            "\n",
            "James Foulds heads the Latent Lab in the IS department. It carries out research in the area of socially conscious machine learning and artificial intelligence. Its work aims to improve AI’s role in society regarding fairness and privacy and to promote the practice of computational social science using probabilistic models and Bayesian inference.\n",
            "\n",
            "Machine Learning for Signal Processing\n",
            "\n",
            "Tulay Adali’s Machine Learning for Signal Processing Lab works on the development of theory and tools for processing signals that arise in today’s growing array of different applications and pose challenges for traditional signal processing techniques. It applies techniques from statistical and adaptive signal processing as well as machine learning to develop effective methods that address challenges in applications with a focus on medical image analysis and fusion.\n",
            "\n",
            "Mobile, Pervasive & Sensor Computing Lab\n",
            "\n",
            "Nirmalya Roy directs the Mobile, Pervasive, and Sensor Computing (MPSC) Lab, which efficiently analyzes data from sensors and mobile devices, uncovers hidden patterns, gauges users’ activity, behavior, and interaction, and presents this to users, society, or applications to better understand human and system behavior.\n",
            "\n",
            "Multi Data Lab\n",
            "\n",
            "Vandana Janeja’s lab has a grant portfolio across multiple projects, leading to significant societal impacts. Multi-domain relevance is evident in all social impact areas, such as climate change and misinformation detection. Data is often multi-resolution, collected with multi-modal mechanisms, multi-dimensional, and comes from multiple disciplines. The lab deals with the heterogeneity in multiple aspects of data, working across disciplines, leading to social impact.\n",
            "\n",
            "NLP and Social Computing Lab\n",
            "\n",
            "The NLP and Social Computing is led by Shimei Pan and focuses on natural language processing (NLP), large-scale social media analytics, Human-AI interaction and societal Impact, and Intelligent Interactive systems\n",
            "\n",
            "Cognitive Vision Group\n",
            "\n",
            "Directed by Tejas Gokhale, the Cognitive Vision Group works on the conceptual characterization of visual scenes, broadly in the areas of computational perception, learning, and reasoning. Areas of innovation include visual understanding in the absence of complete information; adaptating and generalizing to new concepts, cotexts, domains, environments, and tasks; extrapolation across space and time; interpreting and predicting behavior; acquisition and communication of visual knowledge from/with/to other agents and humans.\n",
            "\n",
            "Remote Sensing, Signal & Image Processing\n",
            "\n",
            "Professor Chein-I Chang founded the RSSIPL Lab in 1992. Its research focuses on remote sensing, signal and image processing, specifically hyperspectral imaging, medical imaging, and automatic target recognition.\n",
            "\n",
            "SONG Lab\n",
            "\n",
            "The Security and Optimization for Networked Globe Lab is led by Houbing Herbert Song and has the mission to advance research and education through discovery and innovation at the confluence of AI/machine learning/data science, cybersecurity, and cyber-physical systems (CPS).\n",
            "\n",
            "Trustworthy and Intelligent Computing Lab\n",
            "\n",
            "Professor Keke Chen’s Trustworthy and Intelligent Computing Lab covers security and privacy issues in AI, data mining and scalable learning algorithms, social data analytics, learning to rank and domain adaptation, and cloud computing and distributed systems.\n",
            "\n",
            "Vinjamuri Lab\n",
            "\n",
            "The Vinamuri Lab studies Brain-Machine Interfaces (BMIs) that control upper-limb prostheses. A current research objective is understanding how the brain controls complex hand movements. The human hand has about 30 dimensions, compared to the human arm, which has only seven. BMIs that control human arms have already been demonstrated with decent accuracy.\n",
            "\n",
            "VLSI-SOC Group\n",
            "\n",
            "The primary research areas include Electronic Design and Automation, Brain-inspired computing, Neural network architecture exploration, Autonomous driving and CAN security, digital, analog, and mixed-signal CMOS ICs/SOCs for a variety of applications, Verification and testing techniques, CAD tools for design and analysis of microprocessors and FPGAs, and interdisciplinary research projects.\n",
            "\n",
            "Brain-computer interfaces could let people control robotic arms by thought alone. Ramana Vinjamuri, CC BY-ND\n",
            "\n",
            " \n",
            "\n",
            "UMBC has more than 50 faculty and senior research staff associated with the UMBC Center for Artificial Intelligence, whose research includes work on AI-related problems and techniques. They come from departments, centers, and institutes across UMBC and represent many disciplines.\n",
            "\n",
            "Tülay Adali (CSEE): machine learning for signal processing and bioinformatics\n",
            "Nilanjan Banerjee (CSEE): smart cyber-physical systems, robotics, manufacturing\n",
            "Justin Brooks (CSEE): computational and behavioral neuroscience, medical applications of AI\n",
            "Chien I. Chang (CSEE): remote sensing, image processing\n",
            "Ansu Chatterjee (Math & Statistics): Foundations of data sciences, ethical AI, Bayesian and conditional inference, digital twins and personalized healthcare, climate analytics\n",
            "Keke Chen (CSEE): Privacy and security of AI, data mining/machine learning, and distributed systems\n",
            "Lujie (Karen) Chen (IS): multimodal learning analytics, machine learning, data science, medical informatics\n",
            "Zhiyuan Chen (IS): data mining, adversarial learning, semantic information\n",
            "Jim Clavin (Hilltop): AI for healthcare informatics, byzantine fault tolerance, knowledge graphs, generative AI\n",
            "Mohammad ‘Khash’ Donyaee (CSEE, Lecturer): AI, machine learning\n",
            "Abhijit Dutt (CSEE, Professor of Practice): data science, AI, machine learning\n",
            "Don Engel (CSEE, VP Research): visualization, computer vision, NLP\n",
            "Frank Ferraro (CSEE): natural language understanding (NLP), machine learning\n",
            "Tim Finin (CSEE): Knowledge graphs, knowledge representation and reasoning, human language technology, AI\n",
            "James Foulds (IS): socially conscious machine learning and artificial intelligence\n",
            "Manas Gaur (CSEE): Knowledge graphs and machine learning for NLP, recommender systems, and computational social data science\n",
            "Md Osman Gani (IS): explainable AI, ubiquitous computing, indoor localization, healthcare, and human activity recognition\n",
            "Aryya Gangopadhyay (IS): data mining, healthcare analytics\n",
            "Matthias Gobbert (Math): Machine learning, big data applications in science & engineering, parallel algorithms for computing clusters\n",
            "Ankit Goel (ME): control systems, data-driven learning for complex control systems.\n",
            "Tejas Gokhale (CSEE): computer vision, machine learning, reasoning\n",
            "Milton Halem (CSEE): Big data for climate, quantum computing for AI\n",
            "Morgan Henderson (Hilltop): predictive modeling and causal inference using administrative health data for populations in Maryland\n",
            "Riadul Islam (CSEE): Robust, secured IC design for neuromorphic computing and machine learning applications\n",
            "Vandana Janeja (IS): data science, data mining, anomaly detection\n",
            "Ben Johnson (CSEE, Lecturer): AI, NLP, machine learning\n",
            "Tyler Josephson (CBEE): AI, logic, machine learning, molecular simulation, applications in chemical and environmental engineering\n",
            "Anupam Joshi (CSEE, Dean): AI for cybersecurity & cyber-physical systems, Web/text analysis, semantic web, neural networks\n",
            "Karuna Joshi (IS): data science,  knowledge graphs, regulatory and legal AI, data security and privacy compliance, cloud computing\n",
            "Kostas Kalpakis (CSEE): data science, algorithms for knowledge graphs, machine learning\n",
            "George Karabatis (IS): data science, semantic information integration, machine learning\n",
            "Seung-Jun Kim (CSEE):  machine learning, applications to communications, future power systems, and big data analytics\n",
            "Andrea Kleinsmith (IS): affective computing and human-computer interaction\n",
            "Dong Li (CSEE): Wireless Sensing, Mobile Computing, Wearable Sensing, Multi-model Sensing, Smart Health\n",
            "Chenchen Liu (CSEE): high-performance computing for AI, machine learning\n",
            "Christine Mallinson (LLC): identifying linguistic bias and misinformation\n",
            "Christopher Marron (CSEE), Professor of Practice): machine learning, data science\n",
            "Lara Martin (CSEE): Human‑centered AI, computational creativity, language understanding, neuro-symbolic methods, speech processing, affective computing, conversational agents\n",
            "Cynthia Matuszek (CSEE): robotics, human-robot interaction, machine learning, NLP, cybersecurity\n",
            "Eric Millikin (Visual Arts): AI and art, virtual reality\n",
            "Charles Nicholas (CSEE): machine learning and data science  for malware detection, intelligent information systems\n",
            "Thu Nguyen (Math): machine learning, stochastic approximation\n",
            "Timothy Nohe (Visual Arts): natural language image, video & music generation; ethical and fair use of these tools, visual biases & tropes in AI image generation.\n",
            "Tim Oates (CSEE): machine learning, AI\n",
            "Patti Ordóñez (IS): machine learning, data mining, and visualization to multivariate time series analysis, clinical informatics, biomedical data science\n",
            "Shimei Pan (IS): NLP, machine learning, data mining\n",
            "Sanjay Purushotham (IS): machine learning for healthcare\n",
            "Nirmalya Roy (IS): machine learning for mobile, pervasive, and sensor computing, autonomous systems\n",
            "Jinglai Shen (Math): machine learning, optimization\n",
            "John Schumacher (Sociology, Anthropology, and Public Health): generative AI, pedagogy, gerontology, healthcare delivery\n",
            "Ergun Simsek (CSEE): machine learning for applications in photonics and electromagnetics\n",
            "Jennifer Sleeman (CSEE): NLP, document understanding, machine learning\n",
            "KMA Solaiman (CSEE):  machine learning, multimodal data management; applications to data discovery, multimodal information retrieval, uncertainty management, recommender systems, NLP, video feature extraction\n",
            "Houbing Herbert Song (IS): AI/machine learning/big data analytics for cyber-physical systems/IoT, cybersecurity, and privacy\n",
            "Eric J. Stokan (Political Science): NLP, ML, and LLMs for the social sciences\n",
            "Ramana Vinjamuri (CSEE) brain-computer interfaces, machine learning, signal processing\n",
            "Jianwu Wang (IS): data science for climate and manufacturing\n",
            "Mohamed Younis (CSEE): Machine learning for communications, networks, and embedded systems\n",
            "Ali Yousuf (CSEE): AI, machine learning, and data science for healthcare applications\n",
            "Meilin Yu (ME): Computational fluid dynamics, scientific machine learning, high-performance computing\n",
            "Roberto Yus (CSEE): knowledge representation and reasoning, knowledge graphs, IoT, privacy, semantic data management\n",
            "Rebecca Williams (CSEE): immersive media, data visualization, computer vision, computer graphics, brain-computer interface, wearable sensor technology, imaging, and remote sensing\n",
            "\n",
            "Research Centers\n",
            "Center for Accelerated Real Time Analytics (CARTA)\n",
            "\n",
            "CARTA is an NSF sponsored IUCRC center focused on cutting edge inter-disciplinary research in real time analytics using next generation accelerated hardware.\n",
            "\n",
            "Real time analytics is the leading edge of a smart data revolution, pushed by Internet advances in sensor hardware on one side and AI/ML streaming acceleration on the other. CARTA explores the realm streaming applications of Magna Analytics. The center works with next-generation hardware technologies, like the IBM Minsky with onboard GPU accelerated processors and Flash RAM, and smart cyber-physical sensor systems to build cognitive analytics systems and active storage devices for real time analytics. This will lead to the automated ingestion and simultaneous analytics of Big Datasets generated in various domains including cybersecurity, gealthcare, Internet of Things (IoT) and the scientific arena, and the creation of self learning, self correcting “smart” systems.\n",
            "\n",
            "Center for Real-time Distributed Sensing and Autonomy (CARDS)\n",
            "\n",
            "The vision of CARDS is to advance AI-based autonomy in order to deliver safe, effective, and resilient new capabilities across a variety of complex mission types, including search-and-rescue, persistent surveillance, managing, adapting and optimizing smart, connected robots and machinery, and augmenting humans in performing complex analytical and decision-making tasks. These systems are continually getting better, but to achieve their potential, there are still numerous developments required to improve their capability, command and control, interoperability, resiliency and trustworthiness. Inaugural Funding for CARDS is from the  Army Research Lab for the period 2021-2026.\n",
            "\n",
            "Research Labs and Groups\n",
            "Cyber Defense Lab\n",
            "\n",
            "Director: Dr. Alan Sherman\n",
            "Office No. : ITE 224, Lab No. : ITE 228\n",
            "\n",
            "The Cyber Defense Lab (CDL) is the primary cybersecurity research lab within the CSEE department led by Dr. Alan Sherman.  Among other things, CDL hosts an isolated environment where students can research topics that would normally be considered too dangerous or disruptive to network and system resources or to be investigated in other computer labs. CDL meets bi-weekly to host student/faculty presentations on current research and trends.\n",
            "\n",
            "DAta Management & Semantics (DAMS) Research Group\n",
            "\n",
            "Director: Dr. Roberto Yus\n",
            "Office No. : ITE 342, Lab No. : ITE 230\n",
            "\n",
            "The UMBC DAMS Research Group focuses on four main areas of research: Data Management, AI, Privacy, and the Internet of Things. We deal with research challenges in bridging the gap that exists between raw data (e.g., data captured by sensors) and semantically meaningful data that is easily understood by people (e.g., inferences extracted from sensor observations). We incorporate semantics and privacy-awareness to data management to design smarter and more responsible systems. Also, we develop prototypes of the approaches/systems designed as part of the research tasks and deploy them in the real world.\n",
            "\n",
            "Discovery, Research, and Experimental Analysis of Malware Lab (DREAM)\n",
            "\n",
            "Director: Dr. Charles Nicholas\n",
            "Office No. : ITE 356, Lab No. : ITE 366\n",
            "\n",
            "The DREAM lab looks at ways of applying machine learning to cybersecurity, and malware analysis in particular. Recent projects involve using tensor decomposition and innovative measures of string similarity to solve practical problems. The lab is also home to UMBC’s very active cyberdefense competition team, AKA the ‘CyberDawgs’.\n",
            "\n",
            "ebiquity\n",
            "\n",
            "Director: Dr. Anupam Joshi\n",
            "Office No. : ITE 328, Lab No. : ITE 332\n",
            "\n",
            "Director: Dr. Tim Finin\n",
            "Office No. : ITE 329, Lab No. : ITE 332, ITE 338\n",
            "\n",
            "ebiquity’s research explores the interactions between mobile and pervasive computing, the (semantic) web and web 2.0/3.0/4.0, multi-agent systems and artificial intelligence, security/privacy/trust, and services. Group members have research interests in areas such as distributed systems, wireless networking, pervasive/mobile systems, ad-hoc networks, knowledge representation and reasoning, data management and databases, information retrieval, machine learning, personalization, security and privacy, web/data-mining, multi-agent systems and HPCC. Lab research is driven by applications in the e-sevices area — context aware environments (meeting rooms, surgical suites), social media and blogosphere, wireless web, VANETs, e-commerce and m-commerce, etc.\n",
            "\n",
            "ECLIPSE Cluster\n",
            "\n",
            "Director: Dr. Nilanjan Banerjee\n",
            "Office No. : ITE 362, Lab No. : ITE 351\n",
            "\n",
            "Director: Dr. Ryan Robucci\n",
            "Office No. : ITE 319, Lab No. : ITE 317\n",
            "\n",
            "The ECLIPSE Cluster comprises groups with shared laboratories, projects, and students: the Mobile, Pervasive, & Sensor Systems Laboratory led by Dr. Nilanjan Banerjee, and the Covail Analog & Digital Systems Research Laboratory, led by Dr. Ryan Robucci.\n",
            "\n",
            "ESNET – Embedded Systems and Networks Laboratory\n",
            "\n",
            "Director: Dr. Mohamed Younis\n",
            "Office No. : ITE 325 G, Lab No. : ITE 391\n",
            "\n",
            "Design and management of wireless sensor networks, network architecture and protocols, underwater communication, MAC and routing protocols for ad-hoc and sensor networks, energy-aware system design, secure communication, fault tolerance, topology management, and applications of sensor and actuator networks.\n",
            "\n",
            "Knowledge, Analytics, Cognitive And Cloud Lab (KnACC)\n",
            "\n",
            "Director: Dr. Karuna Pande Joshi\n",
            "Office No. : ITE 424, Lab No. : ITE 4C7B\n",
            "\n",
            "KnACC lab in the Information Systems Department aims to address challenging issues at the intersection of data science and cloud computing, to include cybersecurity.\n",
            "\n",
            "Trustworthy and Intelligent Computing Lab (TAIC)\n",
            "\n",
            "Director: Dr. Keke Chen\n",
            "Office No. : ITE 360\n",
            "\n",
            "TAIC focuses on security and privacy issues in AI, data mining and scalable learning algorithms; social data analytics; and cloud computing and distributed systems. Its research projects have been supported by NSF, NIH, Northwestern Mutual Data Science Institute, Air Force Research Lab, AFOSR, Yahoo!, Amazon, and the Ohio Board of Regents.\n",
            "        Question: Are there any working opportunities in campus\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "INFO:     66.249.83.87:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: I need help in my homework whom shall I contact? | Intent: Get_Research_Faculty_info\n",
            "Awaiting valid feedback from user.\n",
            "INFO:     66.249.83.86:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: I need help in my homework whom shall I contact? | Intent: Get_Research_Faculty_info\n",
            "Feedback not provided after maximum attempts. Proceeding without feedback.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: You need to answer the user's question.\n",
            "        Use the conversation history to provide a consistent response.\n",
            "        Conversation History: \n",
            "        Context: Assistantship, Financial Aid, and Internships\n",
            "Graduate Tutors/Graders\n",
            "Forms\n",
            "Important Links\n",
            "Academic Conduct\n",
            "And all the other important stuff ==>\n",
            "Who is my academic advisor?\n",
            "If you are a main-campus student, then, If the initial letter of your last name belongs to\n",
            " [A-G] group, then Dr. Ergun Simsek (simsek@umbc.edu) is your academic advisor,\n",
            "[H-M] group, then Dr. Masoud Soroush (masoud.soroush@umbc.edu) is your academic advisor,\n",
            "[N-Z], then your advisor is Dr. Ajinkya Borle (aborle1@umbc.edu)\n",
            "If you are a “Shady Grove” student, then Dr. M. Ali Yousuf (maliyou1@umbc.edu) is your academic advisor.\n",
            "Who is the chair of the Data Science program?\n",
            "At UMBC, the departments have chairs. Since we are a program (not a department), we don’t have a chair. Our Graduate Program Director is Dr. Ergun Simsek (simsek@umbc.edu).\n",
            "I have a problem with/question on X. Whom should I contact (Y)?\n",
            "If X == Academic Matters, then Y = OPP Student Success Team or Your Advisor (see above)\n",
            "\n",
            "Assistantship, Financial Aid, and Internships\n",
            "Graduate Tutors/Gradeers\n",
            "Forms\n",
            "Important Links\n",
            "Academic Conduct and our Zero-Tolerance Policy\n",
            "And all the other important stuff ==>\n",
            "Who is my academic advisor?\n",
            "If you are a main-campus student, then, If the initial letter of your last name belongs to\n",
            " [A-G] group, then Dr. Ergun Simsek (simsek@umbc.edu) is your academic advisor,\n",
            "[H-M] group, then Dr. Masoud Soroush (masoud.soroush@umbc.edu) is your academic advisor,\n",
            "[N-Z], then your advisor is Dr. Ajinkya Borle (aborle1@umbc.edu)\n",
            "If you are a “Shady Grove” student, then Dr. M. Ali Yousuf (maliyou1@umbc.edu) is your academic advisor.\n",
            "Who is the chair of the Data Science program?\n",
            "At UMBC, the departments have chairs. Since we are a program (not a department), we don’t have a chair. Our Graduate Program Director is Dr. Ergun Simsek (simsek@umbc.edu).\n",
            "I have a problem with/question on X. Whom should I contact (Y)?\n",
            "If X == Academic Matters, then Y = Your Advisor (see above)\n",
            "\n",
            "RESEARCH & WRITING\n",
            "As both graduate students and professionals, you will be expected to produce written deliverables that are appropriate for your classroom experience and profession or industry. Therefore, if you think you need assistance with developing and/or “brushing up” on graduate-level research and/or writing skills, UMBC offers a range of resources to help you obtain or polish those critical skills to enable you to succeed fully. If needed, I encourage you to take advantage of these campus resources — they’re here for your benefit:\n",
            "Graduate Student Association Writing Advisor\n",
            "\n",
            "← Back to Directory List\n",
            "Waleed A Youssef\n",
            "Instructor Pt\n",
            "w_youssef@umbc.edu\n",
            "\n",
            "← Back to Directory List\n",
            "James Klucar\n",
            "Instructor Pt\n",
            "klucar@umbc.edu\n",
            "        Question: I need help in my homework whom shall I contact?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "INFO:     66.249.83.86:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: Tell me about the policy analysis pathway | Intent: Get_Course_info\n",
            "Awaiting valid feedback from user.\n",
            "INFO:     66.249.83.68:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: Tell me about the policy analysis pathway | Intent: Get_Course_info\n",
            "Feedback not provided after maximum attempts. Proceeding without feedback.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: You need to answer the user's question about course related and  prerequisites information.\n",
            "         Use the conversation history to provide a consistent response.\n",
            "        Conversation History: \n",
            "        Context: This pathway invites students to develop their skills in data science for use in complex public policy organizations. Research and use of public records in public policy are increasingly intertwined. Citizens will often be asked to believe the products of analytics, or to draw their own conclusions from reports and records available anywhere they have a connection to the internet.\n",
            "State and local governments are charged with making records public, and with making evidence-driven decision-making. Pathway courses focus on analytical skills as well as organizations charged with using data: how they work, and how data analytics are used, the contexts of data production and analytics, and the regulation of data production and use.\n",
            "ECON 600 Policy Consequences of Economic Analysis\n",
            "PUBL 601 Political and Social Context of the Policymaking Process\n",
            "PUBL 603 Theory and Practice of Policy Analysis\n",
            "PUBL 607 Statistical Applications in Evaluation Research\n",
            "\n",
            "The Economics/Econometrics pathway teaches students the theory, methods and tools to analyze economic data. Analytical techniques will include optimization, game theory, duality and dynamic optimization.\n",
            "The pathway will provide the student with the skills needed to work with large data sets, to apply econometric techniques such as Ordinary Least Squares (OLS), Two-Stage Least Squares (2SLS), maximum likelihood estimation, and the analysis of panel data. Students will learn how to use econometric packages such as SAS, STATA, and SPSS. Students will gain hands-on experience working on policy questions using real data.\n",
            "PUBL 604 – Statistical Analysis\n",
            "ECON 601 – Microeconomic Analysis\n",
            "ECON 602 – Macroeconomic Analysis\n",
            "ECON 611 – Advanced Econometric Analysis I\n",
            "ECON 612 – Advanced Econometric Analysis II\n",
            "ECON 652 – Economics of Health\n",
            "\n",
            "The pathways will allow students who work in a particular domain to take classes specific to their industry. Students are recommended to choose a pathway and take three courses from the same pathway. However, in case of class unavailability, students are welcome to choose courses from different pathways. We offer a bunch of DATA 690 Special Topics classes. Students, who meet the prerequisites of these Special Classes, can take up to 5 Special Topics classes.\n",
            "Elective Data Science Courses\n",
            "Cybersecurity Pathway\n",
            "Economics/Econometrics (Only at the main campus)\n",
            "Healthcare Analytics (Only at the main campus)\n",
            "Policy Analysis (Only at the main campus)\n",
            "Project Management\n",
            "Management Sciences\n",
            "Aging Studies (Online)\n",
            "Advanced Computing and Analytics Pathway (Only at the main campus)\n",
            "Bioinformatics (FAES @ NIH)\n",
            "Clinical Informatics (with UMB)\n",
            "\n",
            "The Cybersecurity pathway provides broad exposure to cybersecurity principles, best practices, and relevant technologies. Its purpose is to offer students from varying technical disciplines foundational knowledge and the preparation to effectively incorporate cybersecurity concepts, thinking, and analysis into their own professional activities.\n",
            "This pathway leads to a Graduate Certificate in Cybersecurity Operations. Students who choose this pathway need to contact the CYBER GPD to learn when these courses will be offered in the following semester(s).\n",
            "Students must take three required cybersecurity courses and one data science elective (DATA 601, 602, or 605). The CYBER courses in order to complete the pathway and get the certificate are\n",
            "CYBR 620 Introduction to Cybersecurity\n",
            "CYBR 650 Managing Cybersecurity Operations\n",
            "CYBR 658 Risk Analysis and Compliance\n",
            "\n",
            "The rapidly growing national and global aging population brings both tremendous opportunities and complex problems. Building the longevity economy and an age-inclusive society requires professionals with an understanding of both data science and the aging studies field. The Aging Studies pathway provides learners with the foundational knowledge of aging and innovation in aging services. This pathway will allow for exploration as to how data can be utilized to address the wants and needs of consumers throughout the lifespan, to address topics such as disease-risk and healthy aging, to provide innovation in environmental design, housing, healthcare, transportation, policies and social programs, and in the study and analysis of how aging trends to identify avenues for innovation and change.\n",
            "Required Courses:\n",
            "AGNG 600: Social and Economic Context of Aging\n",
            "AGNG 604: Policy Foundations of Aging Services\n",
            "Electives:\n",
            "AGNG 620: An Overview of Dementia & Dementia Care Services\n",
            "        Question: Tell me about the policy analysis pathway\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "INFO:     66.249.83.71:0 - \"POST /webhook HTTP/1.1\" 200 OK\n",
            "Received query: yes | Intent: Feedback\n",
            "Feedback received and conversation history saved.\n",
            "INFO:     66.249.83.69:0 - \"POST /webhook HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [1283]\n"
          ]
        }
      ],
      "source": [
        "# Webhook route for DialogFlow fulfillment\n",
        "@app.post(\"/webhook\")\n",
        "async def webhook(request: Request):\n",
        "    global interaction_count, feedback_requested, pending_conversation_data, last_intent, feedback_timeout_counter\n",
        "    # Extract the query and intent from DialogFlow request\n",
        "    req = await request.json()\n",
        "    query = req.get(\"queryResult\", {}).get(\"queryText\", \"\")\n",
        "    intent_name = req.get(\"queryResult\", {}).get(\"intent\", {}).get(\"displayName\", \"\")\n",
        "    parameters = req.get(\"queryResult\", {}).get(\"parameters\", {})\n",
        "    intent_name = get_parent_intent(intent_name)\n",
        "    print(f\"Received query: {query} | Intent: {intent_name}\")\n",
        "\n",
        "    # Check if the user has provided feedback\n",
        "    # **Step 1: Handle Feedback If Previously Requested**\n",
        "    if feedback_requested and pending_conversation_data:\n",
        "        user_input = query.lower().strip().replace(\"'\", \"\").replace(\"\\\"\", \"\")\n",
        "        feedback = None\n",
        "        if user_input in affirmative_responses:\n",
        "            feedback = \"positive\"\n",
        "        elif user_input in negative_responses:\n",
        "            feedback = \"negative\"\n",
        "        else:\n",
        "            # User has not provided feedback yet\n",
        "            # Proceed to handle the user's query but keep prompting for feedback\n",
        "            pass  # We'll handle this below\n",
        "\n",
        "        if feedback is not None:\n",
        "            # Update the pending conversation data with feedback\n",
        "            pending_conversation_data[\"feedback\"] = feedback\n",
        "            # Save the conversation history with feedback\n",
        "            await save_conversation_history(pending_conversation_data)\n",
        "            # Reset flags and clear memory\n",
        "            feedback_requested = False\n",
        "            pending_conversation_data = None\n",
        "            feedback_timeout_counter = 0  # Reset the feedback timeout counter\n",
        "            memory.chat_memory.clear()\n",
        "            response_text = \"Thank you for your feedback!\"\n",
        "            print(\"Feedback received and conversation history saved.\")\n",
        "            return {\"fulfillmentText\": response_text}\n",
        "        else:\n",
        "            # User has not provided valid feedback yet\n",
        "            feedback_timeout_counter += 1\n",
        "            if feedback_timeout_counter >= MAX_FEEDBACK_PROMPTS:\n",
        "                # Give up on prompting for feedback after max attempts\n",
        "                # Save the conversation history without feedback\n",
        "                await save_conversation_history(pending_conversation_data)\n",
        "                feedback_requested = False\n",
        "                pending_conversation_data = None\n",
        "                feedback_timeout_counter = 0\n",
        "                memory.chat_memory.clear()\n",
        "                print(\"Feedback not provided after maximum attempts. Proceeding without feedback.\")\n",
        "                # Proceed to handle the current query as normal\n",
        "            else:\n",
        "                # Prompt the user again for feedback\n",
        "                response_text = \"Could you please provide feedback by replying with 'Yes' or 'No'?If you want to proceed without the feedback ask the question again.\"\n",
        "                print(\"Awaiting valid feedback from user.\")\n",
        "                return {\"fulfillmentText\": response_text}\n",
        "\n",
        "    # **Step 2: Handle Intent Change and Interaction Count**\n",
        "    handle_intent_change(intent_name)\n",
        "    # Determine if the query is a syllabus query\n",
        "    if intent_name == \"Get_Course_info\" and is_syllabus_query(query):\n",
        "        # Handle syllabus query separately\n",
        "        #print(\"True matches criteria\")\n",
        "        result = await handle_syllabus_query(query, parameters,memory)\n",
        "        response_text = result['answer']\n",
        "    else:\n",
        "      # Select the appropriate retriever and prompt based on intent\n",
        "      retriever = select_retriever(intent_name)\n",
        "      prompt = load_prompt(intent_name)\n",
        "\n",
        "      # Initialize the question generation and document response chains\n",
        "      qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "              llm= load_llm(),\n",
        "              retriever=retriever,\n",
        "              memory=memory,\n",
        "              combine_docs_chain_kwargs={'prompt': prompt},\n",
        "              return_source_documents=True,\n",
        "              verbose=True,\n",
        "              rephrase_question=True,\n",
        "         )\n",
        "      # Run the query through the QA chain and get the response\n",
        "      result = qa_chain({\"question\": query, \"chat_history\": get_user_messages(memory)})\n",
        "      response_text = result['answer']\n",
        "\n",
        "    # Extract source documents\n",
        "    source_docs = result.get('source_documents', [])\n",
        "\n",
        "    # Check if the user is asking for the link\n",
        "    if user_is_asking_for_link(query):\n",
        "      # Extract links from source documents\n",
        "      links = extract_links_from_source_docs(source_docs)  # Returns list of URLs or list of (title, URL) tuples\n",
        "      if links:\n",
        "        # Append links to the response using Markdown\n",
        "        response_text += \"\\n\\nHere are the links to the sources:\\n\\n\"\n",
        "\n",
        "        for link in links:\n",
        "            if isinstance(link, tuple):\n",
        "                title, url = link\n",
        "                response_text += f\"- [{title}]({url})\\n\"\n",
        "            else:\n",
        "                response_text += f\"- [{link}]({link})\\n\"\n",
        "      else:\n",
        "        response_text += \"\\n\\nSorry, I couldn't find any links to provide.\"\n",
        "\n",
        "\n",
        "    # Append the feedback prompt if feedback is requested\n",
        "    if feedback_requested:\n",
        "        response_text += \"\\n\\nWas this conversation helpful? Please reply with 'Yes' or 'No'.\"\n",
        "\n",
        "\n",
        "    # Prepare DialogFlow response\n",
        "    response = {\"fulfillmentText\": response_text}\n",
        "\n",
        "    return response\n",
        "\n",
        "# Run the FastAPI app using nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n28l4e5rvW6K",
        "outputId": "a012c7d6-db77-48d0-dd82-c1f93ce4dad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation Entry 1:\n",
            "{\n",
            "    \"intent\": \"Get_Course_info\",\n",
            "    \"chat_history\": [\n",
            "        {\n",
            "            \"type\": \"human\",\n",
            "            \"content\": \"can I get syllabus for data 603\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"ai\",\n",
            "            \"content\": \"| Week | Topic Description |\\n|------|-------------------|\\n| 1    | Distributed computing overview | \\n| 2    | Hadoop File System | \\n| 3    | MapReduce Design Patterns | \\n| 4    | Data Ingest | \\n| 5    | Spark (core) | \\n| 6    | Spark (SQL) | \\n| 7    | Spark (Streaming) | \\n| 8    | Scalable Machine Learning | \\n| 9    | Apache Hive | \\n| 10   | Hbase | \\n| 11   | Yarn | \\n| 12   | Stratosphere and MonetDB | \\n| 13   | Amazon EC2 and Workflow Management | \\n| 14   | Project presentations |\"\n",
            "        }\n",
            "    ],\n",
            "    \"feedback\": \"positive\"\n",
            "}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Conversation Entry 2:\n",
            "{\n",
            "    \"intent\": \"Get_CPT_OPT_info\",\n",
            "    \"chat_history\": [],\n",
            "    \"feedback\": \"negative\"\n",
            "}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Conversation Entry 3:\n",
            "{\n",
            "    \"intent\": \"Get_CPT_OPT_Info\",\n",
            "    \"chat_history\": [],\n",
            "    \"feedback\": \"positive\"\n",
            "}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Conversation Entry 4:\n",
            "{\n",
            "    \"intent\": \"Get_Research_info\",\n",
            "    \"chat_history\": [\n",
            "        {\n",
            "            \"type\": \"human\",\n",
            "            \"content\": \"Tell me more about UMBC AI center\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"ai\",\n",
            "            \"content\": \"The UMBC Center for AI is an interdisciplinary center established at the University of Maryland, Baltimore County in 2024 to support and promote its communities conducting research, application, and education in all areas of Artificial Intelligence. The center has more than 50 faculty members with research interests in AI and related areas, including robotics, machine learning, natural language understanding, data science, image processing, multi-agent systems, large language models, knowledge representation and reasoning, planning, knowledge graphs, and neural networks. These faculty members work in 25 laboratories and research centers across departments and disciplines. The center aims to advance AI research, application, and education within the UMBC community.\"\n",
            "        }\n",
            "    ],\n",
            "    \"feedback\": \"negative\"\n",
            "}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Conversation Entry 5:\n",
            "{\n",
            "    \"intent\": \"Get_Course_info\",\n",
            "    \"chat_history\": [\n",
            "        {\n",
            "            \"type\": \"human\",\n",
            "            \"content\": \"What is the syllabus for Data 604\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"ai\",\n",
            "            \"content\": \"| Week | Topic Description |\\n|------|-------------------|\\n| 1    | Introduction to History of Databases |\\n| 2    | Computer Setup - SQL Express and Management Studio |\\n| 3    | Database Modeling |\\n| 4    | Database Administration |\\n| 5    | SQL Programming |\\n| 6    | Database Connectivity |\\n| 7    | ETL (Extract, Transform, Load) |\\n| 8    | Reporting and Visualization |\\n| 9    | Data Warehouse and OLAP |\\n| 10   | Parallel and GPU Computing |\\n| 11   | Pycuda |\\n| 12   | Big Data and Cloud Computing |\\n| 13   | Hadoop Ecosystem |\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"human\",\n",
            "            \"content\": \"What is the syllabus for data 602\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"ai\",\n",
            "            \"content\": \"| Week | Topic Description |\\n|------|-------------------|\\n| 1    | Course overview: What is Machine Learning? |\\n| 2    | Overview: Hypotheses spaces, Linear Algebra, Probability and Statistics |\\n| 3    | Supervised Learning: Linear vs. Logistic Regression |\\n| 4    | Decision Trees and Naive Bayes |\\n| 5    | Model Validation: Cross-Validation, Performance Measures, Diagnosing Over/Under fitting |\\n| 6    | Feature Engineering: text, categorical data, binning |\\n| 7    | Support Vector Machines, Nearest Neighbor, Linear Discriminant Analysis |\\n| 8    | Bagging, Boosting and Ensemble Methods, and Random Forests |\\n| 9    | Experiment Design, Decisions in Model Selection, Productizing Models |\\n| 10   | Unsupervised learning: agglomerative, divisive, k-means, DBSCAN |\\n| 11   | Dimensionality reduction and visualization in principal component analysis |\\n| 12   | Bayesian Networks |\\n| 13   | Introduction to Neural Networks and Deep Learning |\\n| 14   | Introduction to Reinforcement Learning |\\n| 15   | Final Exam/Project presentations |\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"human\",\n",
            "            \"content\": \"What is the syllabus for data 690 financial data science\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"ai\",\n",
            "            \"content\": \"| Week | Topic Description |\\n|------|-------------------|\\n| 1    | Introduction to Financial Data Science. Overview of course objectives and expectations. Discussion on the role of financial data in decision-making. |\\n| 2    | Data Collection and Preprocessing in Finance. Understanding financial data sources, data cleaning, and data transformation techniques. |\\n| 3    | Statistical Analysis in Finance. Exploring statistical methods commonly used in financial data analysis. |\\n| 4    | Time Series Analysis and Forecasting in Finance. Techniques for analyzing time series data in financial markets and making predictions. |\\n| 5    | Machine Learning Applications in Finance. Introduction to machine learning algorithms and their applications in financial data science. |\\n| 6    | Deep Learning in Finance. Understanding the role of deep learning models in financial data analysis. |\\n| 7    | Midterm Exam |\\n| 8    | Portfolio Management and Risk Analysis. Strategies for portfolio optimization and risk assessment using financial data. |\\n| 9    | Sentiment Analysis and Market Sentiment. Analyzing market sentiment through text data and social media in financial decision-making. |\\n| 10   | Alternative Data and Predictive Modeling. Exploring non-traditional data sources for predictive modeling in finance. |\\n| 11   | Algorithmic Trading and High-Frequency Trading. Understanding automated trading strategies and their implications in financial markets. |\\n| 12   | Financial Data Visualization. Techniques for visualizing financial data to gain insights and communicate findings effectively. |\\n| 13   | Ethical Considerations in Financial Data Science. Discussion on ethical issues and challenges in using financial data for decision-making. |\\n| 14   | Final Project Presentation and Wrap-Up. Presentation of final projects applying concepts learned throughout the course. |\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"human\",\n",
            "            \"content\": \"What is syllabus for data 690 deep learning\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"ai\",\n",
            "            \"content\": \"| Week | Topic Description |\\n|------|-------------------|\\n| 1    | Introduction to Deep Learning. Neural Networks basics. Class Survey |\\n| 2    | Deep Learning Hardware Fundamentals |\\n| 3    | Deep Learning Software Fundamentals |\\n| 4    | Convolutional Neural Networks |\\n| 5    | Recurrent Neural Networks |\\n| 6    | Generative Adversarial Networks |\\n| 7    | Midterm Exam |\\n| 8    | Transfer Learning and Fine-tuning |\\n| 9    | Optimization Algorithms |\\n| 10   | Natural Language Processing with Deep Learning |\\n| 11   | Computer Vision with Deep Learning |\\n| 12   | Deep Learning on the Cloud |\\n| 13   | Ethics in Deep Learning |\\n| 14   | Final Deep Learning Project |\"\n",
            "        }\n",
            "    ],\n",
            "    \"feedback\": \"positive\"\n",
            "}\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def read_conversation_history(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\") as file:\n",
        "            # Read each line, parse as JSON, and store in a list\n",
        "            conversation_history = [json.loads(line) for line in file]\n",
        "\n",
        "        # Print each conversation entry in a structured way\n",
        "        for i, entry in enumerate(conversation_history, 1):\n",
        "            print(f\"Conversation Entry {i}:\")\n",
        "            print(json.dumps(entry, indent=4))  # Pretty-print each JSON entry\n",
        "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"The file '{file_path}' does not exist.\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"The file contains invalid JSON.\")\n",
        "\n",
        "# Usage\n",
        "file_path = \"conversation_history.json\"\n",
        "read_conversation_history(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0CFH9AswutU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
